{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/prasse/work/Projekte/AEye/reading-comprehension/')\n",
    "from rf_baseline  import rf_feature_extraction as rf_feature_extraction\n",
    "import datetime\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow import Variable\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.math import l2_normalize\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling1D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Embedding, Average, Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model(ent_len,num_ent,\n",
    "                 pos_len,num_pos,\n",
    "                 red_pos_len, num_red_pos,\n",
    "                 con_len, num_con,\n",
    "                 num_features,\n",
    "                 fix_len = None, num_fix = None,\n",
    "                 flag_sequence_bilstm = False):\n",
    "    \n",
    "    drop_outs = 0.3\n",
    "    concat_list = []\n",
    "    input_list  = []\n",
    "    \n",
    "    if ent_len is not None:   \n",
    "        x_ent_input = Input(shape=ent_len)\n",
    "        x_ent = Embedding(input_dim = num_ent,\n",
    "                            output_dim = 64)(x_ent_input)\n",
    "        if flag_sequence_bilstm:\n",
    "            x_ent = Bidirectional(LSTM(25, return_sequences = True))(x_ent)\n",
    "            x_ent = Bidirectional(LSTM(25))(x_ent)\n",
    "            x_ent = Dropout(0.3)(x_ent)\n",
    "            x_ent = Dense(50,activation='relu')(x_ent)\n",
    "            x_ent = Dropout(0.3)(x_ent)\n",
    "            x_ent = Dense(20,activation = 'relu')(x_ent) \n",
    "        else:\n",
    "            x_ent_avg = GlobalAveragePooling1D()(x_ent)\n",
    "            x_ent_max = GlobalMaxPool1D()(x_ent)\n",
    "            x_ent = Concatenate()([x_ent_avg,x_ent_max])\n",
    "            x_ent = Dense(64,activation='relu')(x_ent)\n",
    "            x_ent = Dense(32,activation='relu')(x_ent)\n",
    "        concat_list.append(x_ent)\n",
    "        input_list.append(x_ent_input)\n",
    "    \n",
    "    if pos_len is not None:    \n",
    "        x_pos_input = Input(shape=pos_len)\n",
    "        x_pos = Embedding(input_dim = num_pos,\n",
    "                            output_dim = 128)(x_pos_input)\n",
    "        if flag_sequence_bilstm:\n",
    "            x_pos = Bidirectional(LSTM(25, return_sequences = True))(x_pos)\n",
    "            x_pos = Bidirectional(LSTM(25))(x_pos)\n",
    "            x_pos = Dropout(0.3)(x_pos)\n",
    "            x_pos = Dense(50,activation='relu')(x_pos)\n",
    "            x_pos = Dropout(0.3)(x_pos)\n",
    "            x_pos = Dense(20,activation = 'relu')(x_pos)\n",
    "        else:\n",
    "            x_pos_avg = GlobalAveragePooling1D()(x_pos)\n",
    "            x_pos_max = GlobalMaxPool1D()(x_pos)\n",
    "            x_pos = Concatenate()([x_pos_avg,x_pos_max])\n",
    "            x_pos = Dense(128,activation='relu')(x_pos)\n",
    "            x_pos = Dense(64,activation='relu')(x_pos)\n",
    "            x_pos = Dense(32,activation='relu')(x_pos)\n",
    "        concat_list.append(x_pos)\n",
    "        input_list.append(x_pos_input)\n",
    "    \n",
    "    if red_pos_len is not None:\n",
    "        x_red_pos_input = Input(shape=red_pos_len)\n",
    "        x_red_pos = Embedding(input_dim = num_red_pos,\n",
    "                            output_dim = 8)(x_red_pos_input)\n",
    "        if flag_sequence_bilstm:\n",
    "            x_red_pos = Bidirectional(LSTM(25, return_sequences = True))(x_red_pos)\n",
    "            x_red_pos = Bidirectional(LSTM(25))(x_red_pos)\n",
    "            x_red_pos = Dropout(0.3)(x_red_pos)\n",
    "            x_red_pos = Dense(50,activation='relu')(x_red_pos)\n",
    "            x_red_pos = Dropout(0.3)(x_red_pos)\n",
    "            x_red_pos = Dense(20,activation = 'relu')(x_red_pos)\n",
    "        else:\n",
    "            x_red_pos_avg = GlobalAveragePooling1D()(x_red_pos)\n",
    "            x_red_pos_max = GlobalMaxPool1D()(x_red_pos)\n",
    "            x_red_pos = Concatenate()([x_red_pos_avg,x_red_pos_max])\n",
    "            x_red_pos = Dense(128,activation='relu')(x_pos)\n",
    "            x_red_pos = Dense(64,activation='relu')(x_pos)\n",
    "            x_red_pos = Dense(32,activation='relu')(x_pos)\n",
    "        concat_list.append(x_red_pos)\n",
    "        input_list.append(x_red_pos_input)\n",
    "        \n",
    "    if con_len is not None:    \n",
    "        x_con_input = Input(shape=con_len)\n",
    "        x_con = Embedding(input_dim = num_con,\n",
    "                            output_dim = 8)(x_con_input)\n",
    "        if flag_sequence_bilstm:\n",
    "            x_con = Bidirectional(LSTM(25, return_sequences = True))(x_con)\n",
    "            x_con = Bidirectional(LSTM(25))(x_con)\n",
    "            x_con = Dropout(0.3)(x_con)\n",
    "            x_con = Dense(50,activation='relu')(x_con)\n",
    "            x_con = Dropout(0.3)(x_con)\n",
    "            x_con = Dense(20,activation = 'relu')(x_con)\n",
    "        else:\n",
    "            x_con_avg = GlobalAveragePooling1D()(x_con)\n",
    "            x_con_max = GlobalMaxPool1D()(x_con)\n",
    "            x_con = Concatenate()([x_con_avg,x_con_max])\n",
    "            x_con = Dense(128,activation='relu')(x_con)\n",
    "            x_con = Dense(64,activation='relu')(x_con)\n",
    "            x_con = Dense(32,activation='relu')(x_con)\n",
    "        concat_list.append(x_con)\n",
    "        input_list.append(x_con_input)\n",
    "    \n",
    "    if num_features is not None:\n",
    "        x_num_input = Input(shape=num_features)\n",
    "        #x_num = Dense(256,activation='relu')(x_num_input)\n",
    "        #x_num = Dropout(drop_outs)(x_num)\n",
    "        #x_num = Dense(128,activation='relu')(x_num)\n",
    "        #x_num = Dropout(drop_outs)(x_num)\n",
    "        #x_num = Dense(64,activation='relu')(x_num)\n",
    "        x_num = Dropout(drop_outs)(x_num_input)\n",
    "        x_num = Dense(32,activation='relu')(x_num)\n",
    "        concat_list.append(x_num)\n",
    "        input_list.append(x_num_input)\n",
    "        \n",
    "    if fix_len is not None:\n",
    "        x_fix_input = Input(shape=(fix_len,num_fix))\n",
    "        x_fix = Bidirectional(LSTM(25, return_sequences = True),input_shape=input_shape)(x_fix_input)\n",
    "        x_fix = Bidirectional(LSTM(25))(x_fix)\n",
    "        x_fix = Dropout(0.3)(x_fix)\n",
    "        x_fix = Dense(50,activation='relu')(x_fix)\n",
    "        x_fix = Dropout(0.3)(x_fix)\n",
    "        x_fix = Dense(20,activation = 'relu')(x_fix)        \n",
    "        concat_list.append(x_fix)\n",
    "        input_list.append(x_fix_input)\n",
    "    \n",
    "    x_concat = Concatenate()(concat_list)\n",
    "    x_output = Dense(32,activation='relu')(x_concat)\n",
    "    x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "    model = Model(input_list,\n",
    "                outputs=x_output)\n",
    "    opt = Adam()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:47:00.0, compute capability: 8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GPU = 2\n",
    "# select graphic card\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "config = tf.compat.v1.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "tf_session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help_roc_auc(y_true,y_pred):\n",
    "    if len(np.unique(y_true)) == 1:\n",
    "        return .5\n",
    "    else:\n",
    "        return roc_auc_score(y_true,y_pred)\n",
    "\n",
    "# calculate the roc-auc as a metric\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_function(help_roc_auc, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(spit_criterions,labels,\n",
    "            feature_string,feature_names_per_word,\n",
    "            model_name,input_window,\n",
    "            flag_sequence_bilstm = True,\n",
    "            word_in_fixation_order = True,\n",
    "            use_pos_sequence = True,\n",
    "            use_reduced_pos_sequence = True,\n",
    "            use_entity_sequence = True,\n",
    "            use_content_word_sequence = True,\n",
    "            use_numeric = True,\n",
    "            use_fixation_sequence = True,\n",
    "            flag_redo = False):\n",
    "    for split_criterion in spit_criterions:\n",
    "        for label in labels:\n",
    "            model_prefix = str(flag_sequence_bilstm) +\\\n",
    "                '_' + str(word_in_fixation_order) +\\\n",
    "            '_' + str(use_pos_sequence) +\\\n",
    "            '_' + str(use_reduced_pos_sequence) +\\\n",
    "            '_' + str(use_entity_sequence) +\\\n",
    "            '_' + str(use_content_word_sequence) +\\\n",
    "            '_' + str(use_numeric) +\\\n",
    "            '_' + str(use_fixation_sequence) +\\\n",
    "            '_'\n",
    "            save_path=f'/home/prasse/work/Projekte/AEye/reading-comprehension/rf_baseline/results/{model_prefix}{model_name}_{split_criterion}_text_sequence_{label}_{input_window}.csv'\n",
    "            if not flag_redo and os.path.exists(save_path):\n",
    "                continue\n",
    "            SB_SAT_PATH = f'/raid/projects/reich3/reading-comprehension/paper_splits/{input_window}/{split_criterion}/'\n",
    "            split_criterion_dict = {\n",
    "                'subj': 0,\n",
    "                'book': 1,\n",
    "            }\n",
    "            with open('/raid/projects/reich3/reading-comprehension/npy_files/labels_dict.json') as fp:\n",
    "                label_dict = json.load(fp)\n",
    "\n",
    "            if split_criterion == 'book':\n",
    "                num_folds = 4\n",
    "            else:\n",
    "                num_folds = 5\n",
    "            pd_init = pd.DataFrame(\n",
    "                columns=[\n",
    "                    'ahn_baseline',\n",
    "                    'fold0_auc', 'fold1_auc', 'fold2_auc', 'fold3_auc', 'fold4_auc',\n",
    "                    'fold0_tpr', 'fold1_tpr', 'fold2_tpr', 'fold3_tpr', 'fold4_tpr',\n",
    "                    'fold0_fpr', 'fold1_fpr', 'fold2_fpr', 'fold3_fpr', 'fold4_fpr',\n",
    "                    'fold0_y_pred', 'fold1_y_pred', 'fold2_y_pred', 'fold3_y_pred', 'fold4_y_pred',\n",
    "                    'fold0_y_test', 'fold1_y_test', 'fold2_y_test', 'fold3_y_test', 'fold4_y_test',\n",
    "                'avg_auc', 'std_auc']\n",
    "            )\n",
    "            pd_init['ahn_baseline'] = [model_name]\n",
    "\n",
    "            if input_window == 'window':\n",
    "                input_shape = (21, )\n",
    "            elif input_window == 'page':\n",
    "                input_shape = (150, 11)\n",
    "\n",
    "\n",
    "            for fold in range(num_folds):\n",
    "                np.random.seed(fold)\n",
    "                random.seed(fold)\n",
    "                # collect the inputs for train, validation and test\n",
    "                # use only features where flag is True\n",
    "                train_inputs = []\n",
    "                val_inputs   = []\n",
    "                test_inputs  = []\n",
    "                X_train_path = os.path.join(SB_SAT_PATH, f'X_train_{split_criterion}{feature_string}{fold}.npy')\n",
    "                X_train_fix_path = os.path.join(SB_SAT_PATH, f'X_train_{split_criterion}{feature_string}{fold}_fix_data.npy')\n",
    "                y_train_path = os.path.join(SB_SAT_PATH, f'y_train_{split_criterion}{feature_string}{fold}.npy')\n",
    "                x_train_all, y_train_all = np.load(X_train_path), np.load(y_train_path, allow_pickle=True)\n",
    "                x_train_fix_all = np.load(X_train_fix_path)\n",
    "                x_train_fix_postions  = x_train_fix_all[:,:,4]\n",
    "                if normalize_flag:\n",
    "                    scaler = MinMaxScaler()\n",
    "                    fix_scaler = MinMaxScaler()\n",
    "                    x_train_all = scaler.fit_transform(x_train_all.reshape(-1, x_train_all.shape[-1])).reshape(x_train_all.shape)\n",
    "                    x_train_fix_all = fix_scaler.fit_transform(x_train_fix_all.reshape(-1, x_train_fix_all.shape[-1])).reshape(x_train_fix_all.shape)\n",
    "                    x_train_fix_all = np.where(np.isnan(x_train_fix_all), -4, x_train_fix_all)\n",
    "                if split_criterion != 'book':\n",
    "                    outer_cv = KFold(n_splits=4, shuffle=True, random_state=fold)\n",
    "                else:\n",
    "                    outer_cv = KFold(n_splits=3, shuffle=True, random_state=fold)\n",
    "\n",
    "                if split_criterion != 'book-page':\n",
    "                    splitkeys = np.array(sorted(list(set(y_train_all[:, split_criterion_dict[split_criterion]]))))\n",
    "                else:\n",
    "                    splitkeys = y_train_all[:, label_dict[label]]\n",
    "\n",
    "                for train_idx, val_idx in outer_cv.split(splitkeys):\n",
    "                    break\n",
    "\n",
    "                if split_criterion != 'book-page':\n",
    "                    N_train_sub = splitkeys[train_idx]\n",
    "                    N_test_sub = splitkeys[val_idx]\n",
    "\n",
    "                    train_idx = np.where(np.isin(y_train_all[:, split_criterion_dict[split_criterion]], N_train_sub))[0]\n",
    "                    val_idx = np.where(np.isin(y_train_all[:, split_criterion_dict[split_criterion]], N_test_sub))[0]\n",
    "                x_train = x_train_all[train_idx]\n",
    "                y_train = y_train_all[train_idx]\n",
    "                x_val = x_train_all[val_idx]\n",
    "                y_val = y_train_all[val_idx]\n",
    "                y_train_all[val_idx]    \n",
    "\n",
    "                y_train = np.array(y_train[:, label_dict[label]], dtype=int)\n",
    "                y_val = np.array(y_val[:, label_dict[label]], dtype=int)\n",
    "\n",
    "                x_train, feature_names = rf_feature_extraction.get_rf_features_for_word_features(\n",
    "                            x_train,feature_names_per_word,disable = False,\n",
    "                            use_gaze_entropy_features = use_gaze_entropy_features)\n",
    "                x_val, _ = rf_feature_extraction.get_rf_features_for_word_features(\n",
    "                            x_val,feature_names_per_word,disable = False,\n",
    "                            use_gaze_entropy_features = use_gaze_entropy_features)\n",
    "\n",
    "\n",
    "                # Test Data\n",
    "                X_test_path = os.path.join(SB_SAT_PATH, f'X_test_{split_criterion}{feature_string}{fold}.npy')\n",
    "                X_test_fix_path = os.path.join(SB_SAT_PATH, f'X_test_{split_criterion}{feature_string}{fold}_fix_data.npy')\n",
    "                y_test_path = os.path.join(SB_SAT_PATH, f'y_test_{split_criterion}{feature_string}{fold}.npy')\n",
    "                x_test_all, y_test_all = np.load(X_test_path), np.load(y_test_path, allow_pickle=True)\n",
    "                x_test_fix_all = np.load(X_test_fix_path)\n",
    "                x_test_fix_postions  = x_test_fix_all[:,:,4]\n",
    "                if normalize_flag:\n",
    "                    x_test_all = scaler.transform(x_test_all.reshape(-1, x_test_all.shape[-1])).reshape(x_test_all.shape)\n",
    "                    x_test_fix_all = fix_scaler.transform(x_test_fix_all.reshape(-1, x_test_fix_all.shape[-1])).reshape(x_test_fix_all.shape)\n",
    "                    x_test_fix_all = np.where(np.isnan(x_test_fix_all), -4, x_test_fix_all)                \n",
    "                y_test = np.array(y_test_all[:, label_dict[label]], dtype=int)\n",
    "\n",
    "\n",
    "                x_test, _ = rf_feature_extraction.get_rf_features_for_word_features(\n",
    "                            x_test_all,feature_names_per_word,disable = False,\n",
    "                            use_gaze_entropy_features = use_gaze_entropy_features)\n",
    "\n",
    "\n",
    "                # POS + Entity Lists + reduced POS + content word lists\n",
    "                pos_list_list_train, entity_list_list_train, reduced_pos_list_list_train, content_list_list_train, pos_feature_names, entity_feature_names, reduced_pos_feature_names, content_word_feature_names, fix_position_ind_train = rf_feature_extraction.get_watched_pos_entity_lists(\n",
    "                        x_train_all,feature_names_per_word,x_train_fix_postions)\n",
    "                pos_list_list_test, entity_list_list_test, reduced_pos_list_list_test, content_list_list_test, _, _, _, _, fix_position_ind_test = rf_feature_extraction.get_watched_pos_entity_lists(\n",
    "                        x_test_all,feature_names_per_word,x_test_fix_postions)\n",
    "\n",
    "\n",
    "                pos_lens     = [len(pos_list) for pos_list in pos_list_list_train]\n",
    "                fix_lens     = [len(pos_fix_list) for pos_fix_list in fix_position_ind_train]\n",
    "                entity_lens  = [len(ent_list) for ent_list in entity_list_list_train]\n",
    "                max_pos_len  = np.max(pos_lens)\n",
    "                max_ent_len  = np.max(entity_lens)\n",
    "                max_fix_len  = np.max(fix_lens)\n",
    "\n",
    "\n",
    "                # POS\n",
    "                train_pos_matrix, pos_mapping_dict = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                pos_list_list_train,pos_feature_names,max_pos_len)\n",
    "                test_pos_matrix, _ = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                pos_list_list_test,pos_feature_names,max_pos_len,pos_mapping_dict)\n",
    "                train_pos_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                pos_list_list_train,pos_feature_names,max_fix_len,\n",
    "                                pos_mapping_dict, fix_position_ind_train)\n",
    "                test_pos_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                pos_list_list_test,pos_feature_names,max_fix_len,\n",
    "                                pos_mapping_dict, fix_position_ind_test)\n",
    "\n",
    "                # Entity\n",
    "                train_ent_matrix, ent_mapping_dict = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                entity_list_list_train,entity_feature_names,max_ent_len)\n",
    "                test_ent_matrix, _ = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                entity_list_list_test,entity_feature_names,max_ent_len,ent_mapping_dict)\n",
    "                train_ent_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                entity_list_list_train,entity_feature_names,max_fix_len,\n",
    "                                ent_mapping_dict, fix_position_ind_train)\n",
    "                test_ent_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                entity_list_list_test,entity_feature_names,max_fix_len,\n",
    "                                ent_mapping_dict, fix_position_ind_test)\n",
    "\n",
    "                # Reduced POS\n",
    "                train_reduced_pos_matrix, reduced_pos_mapping_dict = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                reduced_pos_list_list_train, reduced_pos_feature_names, max_pos_len)\n",
    "                test_reduced_pos_matrix, _ = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                reduced_pos_list_list_test,reduced_pos_feature_names,max_pos_len,reduced_pos_mapping_dict)\n",
    "                train_reduced_pos_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                reduced_pos_list_list_train,reduced_pos_feature_names,max_fix_len,\n",
    "                                reduced_pos_mapping_dict, fix_position_ind_train)\n",
    "                test_reduced_pos_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                reduced_pos_list_list_test,reduced_pos_feature_names,max_fix_len,\n",
    "                                reduced_pos_mapping_dict, fix_position_ind_test)\n",
    "\n",
    "                # Content Words\n",
    "                train_content_matrix, content_word_mapping_dict = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                content_list_list_train, content_word_feature_names, max_pos_len)\n",
    "                test_content_matrix, _ = rf_feature_extraction.convert_to_sequence_to_nn_input(\n",
    "                                content_list_list_test,content_word_feature_names,max_pos_len,content_word_mapping_dict)\n",
    "                train_content_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                content_list_list_train,content_word_feature_names,max_fix_len,\n",
    "                                content_word_mapping_dict, fix_position_ind_train)\n",
    "                test_content_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                                content_list_list_test,content_word_feature_names,max_fix_len,\n",
    "                                content_word_mapping_dict, fix_position_ind_test)\n",
    "\n",
    "                num_pos          = len(pos_mapping_dict) + 1\n",
    "                num_ent          = len(ent_mapping_dict) + 1\n",
    "                num_reduced_pos  = len(reduced_pos_mapping_dict) + 1\n",
    "                num_content_word = len(content_word_mapping_dict) + 1\n",
    "\n",
    "\n",
    "                val_pos_fix_matrix   = train_pos_fix_matrix[val_idx]\n",
    "                train_pos_fix_matrix = train_pos_fix_matrix[train_idx]\n",
    "                test_pos_fix_matrix  = test_pos_fix_matrix\n",
    "\n",
    "                val_ent_fix_matrix   = train_ent_fix_matrix[val_idx]\n",
    "                train_ent_fix_matrix = train_ent_fix_matrix[train_idx]\n",
    "                test_ent_fix_matrix  = test_ent_fix_matrix\n",
    "\n",
    "                val_reduced_pos_fix_matrix   = train_reduced_pos_fix_matrix[val_idx]\n",
    "                train_reduced_pos_fix_matrix = train_reduced_pos_fix_matrix[train_idx]\n",
    "                test_reduced_pos_fix_matrix  = test_reduced_pos_fix_matrix\n",
    "\n",
    "                val_content_fix_matrix       = train_content_fix_matrix[val_idx]\n",
    "                train_content_fix_matrix     = train_content_fix_matrix[train_idx]\n",
    "                test_content_fix_matrix      = test_content_fix_matrix\n",
    "\n",
    "                val_pos_matrix   = train_pos_matrix[val_idx]\n",
    "                train_pos_matrix = train_pos_matrix[train_idx]\n",
    "                test_pos_matrix  = test_pos_matrix\n",
    "\n",
    "                val_ent_matrix   = train_ent_matrix[val_idx]\n",
    "                train_ent_matrix = train_ent_matrix[train_idx]\n",
    "                test_ent_matrix  = test_ent_matrix\n",
    "\n",
    "                val_reduced_pos_matrix   = train_reduced_pos_matrix[val_idx]\n",
    "                train_reduced_pos_matrix = train_reduced_pos_matrix[train_idx]\n",
    "                test_reduced_pos_matrix  = test_reduced_pos_matrix\n",
    "\n",
    "                val_content_matrix       = train_content_matrix[val_idx]\n",
    "                train_content_matrix     = train_content_matrix[train_idx]\n",
    "                test_content_matrix      = test_content_matrix\n",
    "\n",
    "\n",
    "                train_fix_matrix   = x_train_fix_all[:,:,:-1]\n",
    "                val_fix_matrix     = train_fix_matrix[val_idx]\n",
    "                train_fix_matrix   = train_fix_matrix[train_idx]\n",
    "                test_fix_matrix    = x_test_fix_all[:,:,:-1]\n",
    "\n",
    "                ent_len         = train_ent_matrix.shape[1]\n",
    "                pos_len         = train_pos_matrix.shape[1]\n",
    "                reduced_pos_len = train_reduced_pos_matrix.shape[1]\n",
    "                content_len     = train_content_matrix.shape[1]\n",
    "                num_features    = x_train.shape[1]\n",
    "                num_fix         = train_fix_matrix.shape[2]\n",
    "                fix_len         = train_fix_matrix.shape[1]\n",
    "\n",
    "                # scale the RF input\n",
    "                rf_input_scaler = MinMaxScaler()\n",
    "                x_train         = rf_input_scaler.fit_transform(x_train)\n",
    "                x_val           = rf_input_scaler.transform(x_val)\n",
    "                x_test          = rf_input_scaler.transform(x_test)\n",
    "                \n",
    "                \n",
    "                # create input lists\n",
    "                if use_entity_sequence:\n",
    "                    if word_in_fixation_order:\n",
    "                        train_inputs.append(train_ent_fix_matrix)\n",
    "                        val_inputs.append(val_ent_fix_matrix)\n",
    "                        test_inputs.append(test_ent_fix_matrix)\n",
    "                        ent_len = train_ent_fix_matrix.shape[1]\n",
    "                        num_ent = len(ent_mapping_dict) + 1\n",
    "                    else:\n",
    "                        train_inputs.append(train_ent_matrix)\n",
    "                        val_inputs.append(val_ent_matrix)\n",
    "                        test_inputs.append(test_ent_matrix)\n",
    "                        ent_len = train_ent_matrix.shape[1]\n",
    "                        num_ent = len(ent_mapping_dict) + 1\n",
    "                else:\n",
    "                    ent_len = None\n",
    "                    num_ent = None\n",
    "                        \n",
    "                if use_pos_sequence:\n",
    "                    if word_in_fixation_order:\n",
    "                        train_inputs.append(train_pos_fix_matrix)\n",
    "                        val_inputs.append(val_pos_fix_matrix)\n",
    "                        test_inputs.append(test_pos_fix_matrix)\n",
    "                        pos_len = train_pos_fix_matrix.shape[1]\n",
    "                        num_pos = len(pos_mapping_dict) + 1\n",
    "                    else:\n",
    "                        train_inputs.append(train_pos_matrix)\n",
    "                        val_inputs.append(val_pos_matrix)\n",
    "                        test_inputs.append(test_pos_matrix)\n",
    "                        pos_len = train_pos_matrix.shape[1]\n",
    "                        num_pos = len(pos_mapping_dict) + 1\n",
    "                else:\n",
    "                    pos_len = None\n",
    "                    num_pos = None\n",
    "                \n",
    "                if use_reduced_pos_sequence:\n",
    "                    if word_in_fixation_order:\n",
    "                        train_inputs.append(train_reduced_pos_fix_matrix)\n",
    "                        val_inputs.append(val_reduced_pos_fix_matrix)\n",
    "                        test_inputs.append(test_reduced_pos_fix_matrix)\n",
    "                        reduced_pos_len = train_reduced_pos_fix_matrix.shape[1]\n",
    "                        num_pos_reduced = len(reduced_pos_mapping_dict) + 1\n",
    "                    else:\n",
    "                        train_inputs.append(train_reduced_pos_matrix)\n",
    "                        val_inputs.append(val_reduced_pos_matrix)\n",
    "                        test_inputs.append(test_reduced_pos_matrix)\n",
    "                        reduced_pos_len = train_reduced_pos_matrix.shape[1]\n",
    "                        num_pos_reduced = len(reduced_pos_mapping_dict) + 1\n",
    "                else:\n",
    "                    reduced_pos_len = None\n",
    "                    num_pos_reduced = None\n",
    "                \n",
    "                if use_content_word_sequence:\n",
    "                    if word_in_fixation_order:\n",
    "                        train_inputs.append(train_content_fix_matrix)\n",
    "                        val_inputs.append(val_content_fix_matrix)\n",
    "                        test_inputs.append(test_content_fix_matrix)\n",
    "                        content_len = train_content_fix_matrix.shape[1]\n",
    "                        num_content = len(content_word_mapping_dict) + 1\n",
    "                    else:\n",
    "                        train_inputs.append(train_content_matrix)\n",
    "                        val_inputs.append(val_content_matrix)\n",
    "                        test_inputs.append(test_content_matrix)\n",
    "                        content_len = train_content_matrix.shape[1]\n",
    "                        num_content = len(content_word_mapping_dict) + 1\n",
    "                else:\n",
    "                    content_len = None\n",
    "                    num_content = None\n",
    "                \n",
    "                if use_numeric:\n",
    "                    train_inputs.append(x_train)\n",
    "                    val_inputs.append(x_val)\n",
    "                    test_inputs.append(x_test)\n",
    "                    num_features = x_train.shape[1]\n",
    "                else:\n",
    "                    num_features = None\n",
    "                \n",
    "                if use_fixation_sequence:\n",
    "                    train_inputs.append(train_fix_matrix)\n",
    "                    val_inputs.append(val_fix_matrix)\n",
    "                    test_inputs.append(test_fix_matrix)\n",
    "                    fix_len = train_fix_matrix.shape[1]\n",
    "                    num_fix = train_fix_matrix.shape[2]\n",
    "                else:\n",
    "                    fix_len = None\n",
    "                    num_fix = None\n",
    "                \n",
    "                model = get_nn_model(ent_len,num_ent,\n",
    "                                     pos_len,num_pos,\n",
    "                                     reduced_pos_len, num_pos_reduced,\n",
    "                                     content_len, num_content,\n",
    "                                     num_features,\n",
    "                                     num_fix = num_fix,\n",
    "                                     fix_len = fix_len)\n",
    "\n",
    "                tf.keras.backend.clear_session()\n",
    "                callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "                history = model.fit(train_inputs,y_train,\n",
    "                                             validation_data = (\n",
    "                                                 val_inputs,\n",
    "                                                 y_val),\n",
    "                                             batch_size = batch_size,\n",
    "                                             epochs = epochs,\n",
    "                                             callbacks = callbacks,\n",
    "                                             verbose = 0)\n",
    "\n",
    "\n",
    "                y_pred = model.predict(test_inputs,\n",
    "                                       batch_size = batch_size)\n",
    "                try:\n",
    "                    fpr, tpr, _ = metrics.roc_curve(\n",
    "                        y_test,\n",
    "                        y_pred,\n",
    "                        pos_label=1,\n",
    "                    )\n",
    "                    auc = metrics.auc(fpr, tpr)\n",
    "                    print(auc)\n",
    "                    pd_init[f'fold{fold}_auc'] = auc\n",
    "                    pd_init[f'fold{fold}_tpr'] = [tpr]\n",
    "                    pd_init[f'fold{fold}_fpr'] = [fpr]\n",
    "                    pd_init[f'fold{fold}_y_test'] = [y_test]\n",
    "                    pd_init[f'fold{fold}_y_pred'] = [y_pred]\n",
    "                except:\n",
    "                    try:\n",
    "                        fpr, tpr, _ = metrics.roc_curve(\n",
    "                            y_test,\n",
    "                            y_pred,\n",
    "                            pos_label=1,\n",
    "                        )\n",
    "                        auc = metrics.auc(fpr, tpr)\n",
    "                        print(auc)\n",
    "                        pd_init[f'fold{fold}_auc'] = auc\n",
    "                        pd_init[f'fold{fold}_tpr'] = [tpr]\n",
    "                        pd_init[f'fold{fold}_fpr'] = [fpr]\n",
    "                        pd_init[f'fold{fold}_y_test'] = y_test\n",
    "                        pd_init[f'fold{fold}_y_pred'] = y_pred\n",
    "                    except:\n",
    "                        print(allo)\n",
    "\n",
    "            pd_init['avg_auc'] = 0\n",
    "            for i in range(num_folds):\n",
    "                pd_init['avg_auc'] += pd_init[f'fold{i}_auc']\n",
    "            pd_init['avg_auc']  /= num_folds\n",
    "\n",
    "            pd_init['std_auc'] = 0\n",
    "            for i in range(0, num_folds):\n",
    "                pd_init['std_auc'] +=  (pd_init[f'fold{i}_auc'] - pd_init['avg_auc'])**2\n",
    "            pd_init['std_auc'] = (pd_init['std_auc']/num_folds)**(1/2)\n",
    "            pd_init.to_csv(save_path, index=None)\n",
    "            print('mean auc: ' + str(pd_init['avg_auc']))\n",
    "        #print(allo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_flag = True\n",
    "use_gaze_entropy_features = True\n",
    "input_window = 'page'\n",
    "num_words = 150\n",
    "\n",
    "flag_redo = False\n",
    "patience = 50\n",
    "batch_size = 256\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_sequence_bilstm = [True,False]\n",
    "word_in_fixation_orders = [True,False]\n",
    "use_pos_sequences = [True,False]\n",
    "use_reduced_pos_sequences = [True,False]\n",
    "use_entity_sequences = [True,False]\n",
    "use_content_word_sequences = [True,False]\n",
    "use_numerics = [True,False]\n",
    "use_fixation_sequences = [True,False]\n",
    "\n",
    "spit_criterions = ['book-page', 'subj','book']\n",
    "labels = ['subj_acc_level', 'acc_level','native','difficulty']\n",
    "model_name = 'nn_paul'\n",
    "\n",
    "feature_names_per_word = [      'ff',\n",
    "                                'tf',\n",
    "                                'wfc_ff_nomarlized',\n",
    "                                'wfc_ff_normalized',\n",
    "                                'sc_ff_normalized',\n",
    "                                'sc_tf_normalized',\n",
    "                                'ic_ff_normalized',\n",
    "                                'regression',\n",
    "                                'num_regressions',\n",
    "                                'num_progressions',\n",
    "                                'surprisal',\n",
    "                                'word_len',\n",
    "                                'dependencies_right',\n",
    "                                'dependencies_left']\n",
    "    \n",
    "\n",
    "for entity in rf_feature_extraction.entity_list:\n",
    "    feature_names_per_word.append('is_entity_' + entity)\n",
    "\n",
    "for pos in rf_feature_extraction.pos_list:\n",
    "    feature_names_per_word.append('is_pos_' + pos)\n",
    "    \n",
    "\n",
    "unique_content_word_list = list(np.unique(list(rf_feature_extraction.content_word_dict.values())))\n",
    "for content_word in unique_content_word_list:\n",
    "    feature_names_per_word.append('is_content_word_' + content_word)\n",
    "\n",
    "\n",
    "unique_reduced_pos_list = list(np.unique(list(rf_feature_extraction.reduced_pos_dict.values())))\n",
    "for r_pos in unique_reduced_pos_list:\n",
    "    feature_names_per_word.append('is_reduced_pos_' + r_pos)\n",
    "\n",
    "feature_names_per_word += ['x_mean','y_mean']\n",
    "\n",
    "feature_string = '_text_sequence_'\n",
    "feature_string = '_text_sequence_with_paul_david_cluster_'\n",
    "feature_string = '_text_sequence_with_paul_david_cluster_41_feature_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [00:06<00:00, 201.72it/s]\n",
      "100%|██████████| 418/418 [00:02<00:00, 201.02it/s]\n",
      "100%|██████████| 418/418 [00:02<00:00, 201.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6653454003895062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [00:06<00:00, 202.04it/s]\n",
      "100%|██████████| 418/418 [00:02<00:00, 202.15it/s]\n",
      "100%|██████████| 418/418 [00:02<00:00, 202.82it/s]\n",
      "  0%|          | 0/1254 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7019237447044935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1254/1254 [00:06<00:00, 202.74it/s]\n",
      "100%|██████████| 418/418 [00:02<00:00, 203.06it/s]\n",
      "100%|██████████| 418/418 [00:02<00:00, 200.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-34047eee826c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0muse_numeric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muse_numerics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0muse_fixation_sequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muse_fixation_sequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                 train_nn(spit_criterions = spit_criterions,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                             \u001b[0mfeature_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_string\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e212a70e8378>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(spit_criterions, labels, feature_string, feature_names_per_word, model_name, input_window, flag_sequence_bilstm, word_in_fixation_order, use_pos_sequence, use_reduced_pos_sequence, use_entity_sequence, use_content_word_sequence, use_numeric, use_fixation_sequence, flag_redo)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 history = model.fit(train_inputs,y_train,\n\u001b[0m\u001b[1;32m    352\u001b[0m                                              validation_data = (\n\u001b[1;32m    353\u001b[0m                                                  \u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1215\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 719\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3118\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3121\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for flag_sequence_bilstm in flags_sequence_bilstm:\n",
    "    for word_in_fixation_order in word_in_fixation_orders:\n",
    "        for use_pos_sequence in use_pos_sequences:\n",
    "            for use_reduced_pos_sequence in use_reduced_pos_sequences:\n",
    "                for use_entity_sequence in use_entity_sequences:\n",
    "                    for use_content_word_sequence in use_content_word_sequences:\n",
    "                        for use_numeric in use_numerics:\n",
    "                            for use_fixation_sequence in use_fixation_sequences:\n",
    "                                train_nn(spit_criterions = spit_criterions,\n",
    "                                            labels = labels,\n",
    "                                            feature_string = feature_string,\n",
    "                                            feature_names_per_word = feature_names_per_word,\n",
    "                                            model_name = model_name,\n",
    "                                            input_window = input_window,\n",
    "                                            flag_sequence_bilstm = flag_sequence_bilstm,\n",
    "                                            word_in_fixation_order = word_in_fixation_order,\n",
    "                                            use_pos_sequence = use_pos_sequence,\n",
    "                                            use_reduced_pos_sequence = use_reduced_pos_sequence,\n",
    "                                            use_entity_sequence = use_entity_sequence,\n",
    "                                            use_content_word_sequence = use_content_word_sequence,\n",
    "                                            use_numeric = use_numeric,\n",
    "                                            use_fixation_sequence = use_fixation_sequence,\n",
    "                                            flag_redo = flag_redo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1254, 564)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 398, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fix_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1254, 391)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reduced_pos_fix_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c24ff2e3d7f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'allo' is not defined"
     ]
    }
   ],
   "source": [
    "print(allo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fix_postions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_fix_matrix = rf_feature_extraction.convert_to_sequence_to_nn_input_fixation(\n",
    "                            pos_list_list_train,pos_feature_names,max_fix_len,\n",
    "                            pos_mapping_dict, fix_position_ind_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_fix_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_position_ind_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list_list_train[0][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_list_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fix_position_ind_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_position_ind_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = ['', 'DATE', 'QUANTITY', 'ORG', 'GPE', 'NORP', 'PERSON', 'TIME', 'CARDINAL', 'ORDINAL', 'NaN']\n",
    "pos_list    = ['PUNCT', 'PROPN', 'NOUN', 'PRON', 'VERB', 'SCONJ', 'NUM', 'DET', 'CCONJ', 'ADP', 'AUX', 'ADV', 'ADJ', 'INTJ', 'X', 'PART']\n",
    "\n",
    "content_word_dict = {'PUNCT':'NO_CONTENT',\n",
    "                    'PROPN':'CONTENT',\n",
    "                    'NOUN':'CONTENT',\n",
    "                    'PRON':'NO_CONTENT',\n",
    "                    'VERB':'CONTENT',\n",
    "                    'SCONJ':'NO_CONTENT',\n",
    "                    'NUM':'NO_CONTENT',\n",
    "                    'DET':'NO_CONTENT',\n",
    "                    'CCONJ':'NO_CONTENT',\n",
    "                    'ADP':'NO_CONTENT',\n",
    "                    'AUX':'NO_CONTENT',\n",
    "                    'ADV':'CONTENT',\n",
    "                    'ADJ':'CONTENT',\n",
    "                    'INTJ':'NO_CONTENT',\n",
    "                    'X':'NO_CONTENT',\n",
    "                    'PART':'NO_CONTENT',\n",
    "                    'NaN':'UNKNOWN'}\n",
    "                    \n",
    "reduced_pos_dict = {'PUNCT':'FUNC',\n",
    "                    'PROPN':'NOUN',\n",
    "                    'NOUN':'NOUN',\n",
    "                    'PRON':'FUNC',\n",
    "                    'VERB':'VERB',\n",
    "                    'SCONJ':'FUNC',\n",
    "                    'NUM':'FUNC',\n",
    "                    'DET':'FUNC',\n",
    "                    'CCONJ':'FUNC',\n",
    "                    'ADP':'FUNC',\n",
    "                    'AUX':'FUNC',\n",
    "                    'ADV':'ADJ',\n",
    "                    'ADJ':'ADJ','INTJ':'FUNC',\n",
    "                    'X':'FUNC',\n",
    "                    'PART':'FUNC',\n",
    "                    'NaN':'UNKNOWN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, input_feature_names, fix_postions = x_train_all,feature_names_per_word,x_train_fix_postions\n",
    "\n",
    "pos_list_list          = []\n",
    "entity_list_list       = []\n",
    "reduced_pos_list_list  = []\n",
    "content_list_list      = []\n",
    "position_ind_list_list = []\n",
    "\n",
    "pos_feature_names = []\n",
    "pos_feature_ids   = []\n",
    "entity_feature_names = []\n",
    "entity_feature_ids = []\n",
    "reduced_pos_feature_names = []\n",
    "reduced_pos_feature_ids = []\n",
    "content_feature_names = []\n",
    "content_feature_ids = []\n",
    "for i in range(len(input_feature_names)):\n",
    "    cur_feature_name = input_feature_names[i]\n",
    "    if cur_feature_name.startswith('is_pos'):\n",
    "        pos_feature_names.append(cur_feature_name)\n",
    "        pos_feature_ids.append(i)\n",
    "    elif cur_feature_name.startswith('is_entity'):\n",
    "        entity_feature_names.append(cur_feature_name)\n",
    "        entity_feature_ids.append(i)\n",
    "    elif cur_feature_name.startswith('is_reduced_pos'):\n",
    "        reduced_pos_feature_names.append(cur_feature_name)\n",
    "        reduced_pos_feature_ids.append(i)\n",
    "    elif cur_feature_name.startswith('is_content_word'):\n",
    "        content_feature_names.append(cur_feature_name)\n",
    "        content_feature_ids.append(i)\n",
    "pos_feature_names = np.array(pos_feature_names + ['UNKNOWN'])\n",
    "entity_feature_names = np.array(entity_feature_names + ['UNKOWN'])\n",
    "reduced_pos_feature_names = np.array(reduced_pos_feature_names + ['UNKOWN'])\n",
    "content_feature_names = np.array(content_feature_names + ['UNKOWN'])\n",
    "\n",
    "\n",
    "for data_id in range(data.shape[0]):\n",
    "    cur_instance = data[data_id]\n",
    "    cur_fix_postions = fix_postions[data_id]\n",
    "    cur_fix_postions[np.isnan(cur_fix_postions)] = -4\n",
    "    pos_list = []\n",
    "    entity_list = []\n",
    "    reduced_pos_list = []\n",
    "    content_list = []\n",
    "    position_ind_list = []\n",
    "    ff_feature_id = int(np.where(np.array(input_feature_names) == 'ff')[0][0])\n",
    "    fixation_ids = np.where(cur_instance[:,ff_feature_id] > 0)[0]\n",
    "    used_word_ids = []\n",
    "    word_id_dict = dict()\n",
    "    for fix_id in range(len(fixation_ids)):\n",
    "        cur_id = fixation_ids[fix_id]\n",
    "        used_word_ids.append(cur_id)\n",
    "        word_id_dict[cur_id] = fix_id\n",
    "        word_feature_vec = cur_instance[cur_id]\n",
    "        #print(word_feature_vec.shape)\n",
    "        # get POS\n",
    "        pos_vec = word_feature_vec[pos_feature_ids]\n",
    "        pos_id = np.where(pos_vec > 0)[0]\n",
    "        if len(pos_id) == 1:\n",
    "            pos_list.append(pos_feature_names[int(pos_id[0])])\n",
    "            reduced_pos_list.append(reduced_pos_dict[pos_feature_names[int(pos_id[0])].replace('is_pos_','')])\n",
    "            content_list.append(content_word_dict[pos_feature_names[int(pos_id[0])].replace('is_pos_','')])                \n",
    "        else:\n",
    "            pos_list.append('UNKNOWN')\n",
    "            reduced_pos_list.append('UNKNOWN')\n",
    "            content_list.append('UNKNOWN')\n",
    "\n",
    "        # get Entity\n",
    "        ent_vec = word_feature_vec[entity_feature_ids]\n",
    "        ent_id = np.where(ent_vec > 0)[0]\n",
    "        if len(ent_id) == 1:\n",
    "            entity_list.append(entity_feature_names[int(ent_id[0])])\n",
    "        else:\n",
    "            entity_list.append('UNKNOWN')\n",
    "    for p_id in range(len(cur_fix_postions)):\n",
    "        try:\n",
    "            position_ind_list.append(word_id_dict[cur_fix_postions[p_id]])\n",
    "        except:\n",
    "            pass\n",
    "    print(allo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_fix_postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(used_word_ids).difference(set(cur_fix_postions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(cur_fix_postions).difference(set(used_word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(cur_fix_postions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_fix_postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_fix_postions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_fix_postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fix_postions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fix_postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_nn_model(            ent_len,num_ent,\n",
    "                                 pos_len,num_pos,\n",
    "                                 reduced_pos_len, num_pos,\n",
    "                                 content_len, num_pos,\n",
    "                                 num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fix_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fix_postions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_nn_model(            ent_len = None,num_ent = None,\n",
    "                                 pos_len = None ,num_pos = None,\n",
    "                                 reduced_pos_len = None, num_pos = None,\n",
    "                                 content_len = None, num_pos = None,\n",
    "                                 num_features,\n",
    "                                 fix_len = x_train, num_fix = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix RNN + our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_nn_model(            ent_len = None,num_ent = None,\n",
    "                                 pos_len = None ,num_pos = None,\n",
    "                                 red_pos_len = None, num_red_pos = None,\n",
    "                                 con_len = None, num_con = None,\n",
    "                                 num_features = num_features,\n",
    "                                 num_fix = num_fix,\n",
    "                                 fix_len = fix_len)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "history = model.fit([#train_ent_matrix,\n",
    "                     #train_pos_matrix,\n",
    "                     #train_reduced_pos_matrix,\n",
    "                     #train_content_matrix,\n",
    "                     x_train,\n",
    "                     train_fix_matrix],y_train,\n",
    "                             validation_data = (\n",
    "                                 [#val_ent_matrix,\n",
    "                                  #val_pos_matrix,\n",
    "                                  #val_reduced_pos_matrix,\n",
    "                                  #val_content_matrix,\n",
    "                                  x_val,\n",
    "                                  val_fix_matrix],\n",
    "                                 y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks,\n",
    "                             verbose = 1)\n",
    "\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "y_pred = model.predict([  #test_ent_matrix,\n",
    "                                      #test_pos_matrix,\n",
    "                                      #test_reduced_pos_matrix,\n",
    "                                      #test_content_matrix,\n",
    "                                      x_test,\n",
    "                                      test_fix_matrix],\n",
    "                                   batch_size = batch_size)\n",
    "fpr, tpr, _ = metrics.roc_curve(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    pos_label=1,\n",
    ")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS input Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 130)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 130, 8)            128       \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 130, 50)           6800      \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 50)                15200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 25,719\n",
      "Trainable params: 25,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 7s 681ms/step - loss: 0.6911 - accuracy: 0.5684 - auroc: 0.5393 - val_loss: 0.6868 - val_accuracy: 0.6421 - val_auroc: 0.4933\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.6814 - accuracy: 0.6737 - auroc: 0.4911 - val_loss: 0.6768 - val_accuracy: 0.6421 - val_auroc: 0.4901\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.6672 - accuracy: 0.6737 - auroc: 0.5232 - val_loss: 0.6634 - val_accuracy: 0.6421 - val_auroc: 0.4780\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.6483 - accuracy: 0.6737 - auroc: 0.5013 - val_loss: 0.6525 - val_accuracy: 0.6421 - val_auroc: 0.4783\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 1s 440ms/step - loss: 0.6408 - accuracy: 0.6737 - auroc: 0.4769 - val_loss: 0.6643 - val_accuracy: 0.6421 - val_auroc: 0.4810\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.6380 - accuracy: 0.6737 - auroc: 0.4997 - val_loss: 0.6566 - val_accuracy: 0.6421 - val_auroc: 0.4923\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.6352 - accuracy: 0.6737 - auroc: 0.4953 - val_loss: 0.6529 - val_accuracy: 0.6421 - val_auroc: 0.4896\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.6283 - accuracy: 0.6737 - auroc: 0.5613 - val_loss: 0.6529 - val_accuracy: 0.6421 - val_auroc: 0.4906\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.6280 - accuracy: 0.6737 - auroc: 0.5586 - val_loss: 0.6539 - val_accuracy: 0.6421 - val_auroc: 0.4873\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 1s 385ms/step - loss: 0.6261 - accuracy: 0.6737 - auroc: 0.5660 - val_loss: 0.6551 - val_accuracy: 0.6421 - val_auroc: 0.4865\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.6247 - accuracy: 0.6737 - auroc: 0.5741 - val_loss: 0.6581 - val_accuracy: 0.6421 - val_auroc: 0.4835\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.6187 - accuracy: 0.6737 - auroc: 0.6175 - val_loss: 0.6571 - val_accuracy: 0.6421 - val_auroc: 0.4799\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 1s 385ms/step - loss: 0.6112 - accuracy: 0.6737 - auroc: 0.6665 - val_loss: 0.6569 - val_accuracy: 0.6421 - val_auroc: 0.4802\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.6002 - accuracy: 0.6737 - auroc: 0.7216 - val_loss: 0.6615 - val_accuracy: 0.6421 - val_auroc: 0.4810\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.5814 - accuracy: 0.6737 - auroc: 0.7564 - val_loss: 0.6732 - val_accuracy: 0.6421 - val_auroc: 0.4828\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 1s 395ms/step - loss: 0.5500 - accuracy: 0.6737 - auroc: 0.7920 - val_loss: 0.6882 - val_accuracy: 0.6421 - val_auroc: 0.4859\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5206 - accuracy: 0.6758 - auroc: 0.7976 - val_loss: 0.6863 - val_accuracy: 0.6421 - val_auroc: 0.4836\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4969 - accuracy: 0.6800 - auroc: 0.8184 - val_loss: 0.7980 - val_accuracy: 0.6421 - val_auroc: 0.4903\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4709 - accuracy: 0.7232 - auroc: 0.8275 - val_loss: 0.8163 - val_accuracy: 0.6263 - val_auroc: 0.4919\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4592 - accuracy: 0.7274 - auroc: 0.8242 - val_loss: 0.8362 - val_accuracy: 0.5772 - val_auroc: 0.4922\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 1s 390ms/step - loss: 0.4649 - accuracy: 0.7547 - auroc: 0.8186 - val_loss: 0.8240 - val_accuracy: 0.5421 - val_auroc: 0.4879\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.4656 - accuracy: 0.7611 - auroc: 0.8007 - val_loss: 0.7499 - val_accuracy: 0.5246 - val_auroc: 0.4918\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.4553 - accuracy: 0.7621 - auroc: 0.8237 - val_loss: 0.8212 - val_accuracy: 0.5544 - val_auroc: 0.5101\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4627 - accuracy: 0.7632 - auroc: 0.8131 - val_loss: 0.7285 - val_accuracy: 0.5140 - val_auroc: 0.5019\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4499 - accuracy: 0.7663 - auroc: 0.8189 - val_loss: 0.7721 - val_accuracy: 0.5421 - val_auroc: 0.5038\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 1s 366ms/step - loss: 0.4445 - accuracy: 0.7600 - auroc: 0.8177 - val_loss: 0.7665 - val_accuracy: 0.5439 - val_auroc: 0.5014\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4469 - accuracy: 0.7726 - auroc: 0.8280 - val_loss: 0.7613 - val_accuracy: 0.5298 - val_auroc: 0.4954\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4407 - accuracy: 0.7695 - auroc: 0.8238 - val_loss: 0.7970 - val_accuracy: 0.5474 - val_auroc: 0.4949\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 1s 389ms/step - loss: 0.4481 - accuracy: 0.7674 - auroc: 0.8297 - val_loss: 0.7375 - val_accuracy: 0.5053 - val_auroc: 0.4979\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4427 - accuracy: 0.7716 - auroc: 0.8258 - val_loss: 0.7556 - val_accuracy: 0.5333 - val_auroc: 0.5042\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4482 - accuracy: 0.7705 - auroc: 0.8298 - val_loss: 0.7718 - val_accuracy: 0.5404 - val_auroc: 0.5047\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 1s 389ms/step - loss: 0.4465 - accuracy: 0.7695 - auroc: 0.8218 - val_loss: 0.7632 - val_accuracy: 0.5368 - val_auroc: 0.5015\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4406 - accuracy: 0.7642 - auroc: 0.8260 - val_loss: 0.7450 - val_accuracy: 0.5105 - val_auroc: 0.4949\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4386 - accuracy: 0.7726 - auroc: 0.8255 - val_loss: 0.7653 - val_accuracy: 0.5263 - val_auroc: 0.4929\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4394 - accuracy: 0.7726 - auroc: 0.8306 - val_loss: 0.7537 - val_accuracy: 0.5070 - val_auroc: 0.4979\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4469 - accuracy: 0.7674 - auroc: 0.8252 - val_loss: 0.7700 - val_accuracy: 0.5316 - val_auroc: 0.5022\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 1s 380ms/step - loss: 0.4506 - accuracy: 0.7726 - auroc: 0.8225 - val_loss: 0.7423 - val_accuracy: 0.5053 - val_auroc: 0.4924\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4382 - accuracy: 0.7726 - auroc: 0.8310 - val_loss: 0.7651 - val_accuracy: 0.5123 - val_auroc: 0.4908\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.4439 - accuracy: 0.7758 - auroc: 0.8246 - val_loss: 0.7483 - val_accuracy: 0.5088 - val_auroc: 0.4958\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4392 - accuracy: 0.7789 - auroc: 0.8341 - val_loss: 0.7617 - val_accuracy: 0.5193 - val_auroc: 0.5057\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4401 - accuracy: 0.7737 - auroc: 0.8195 - val_loss: 0.7470 - val_accuracy: 0.5105 - val_auroc: 0.4957\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 1s 388ms/step - loss: 0.4378 - accuracy: 0.7747 - auroc: 0.8241 - val_loss: 0.7512 - val_accuracy: 0.5123 - val_auroc: 0.4941\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4415 - accuracy: 0.7726 - auroc: 0.8242 - val_loss: 0.7694 - val_accuracy: 0.5158 - val_auroc: 0.4906\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4389 - accuracy: 0.7758 - auroc: 0.8207 - val_loss: 0.7516 - val_accuracy: 0.4965 - val_auroc: 0.4752\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.4415 - accuracy: 0.7779 - auroc: 0.8204 - val_loss: 0.7616 - val_accuracy: 0.5000 - val_auroc: 0.4831\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4339 - accuracy: 0.7779 - auroc: 0.8308 - val_loss: 0.7670 - val_accuracy: 0.5070 - val_auroc: 0.4915\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4322 - accuracy: 0.7758 - auroc: 0.8330 - val_loss: 0.7518 - val_accuracy: 0.5018 - val_auroc: 0.4966\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4325 - accuracy: 0.7779 - auroc: 0.8349 - val_loss: 0.7573 - val_accuracy: 0.5070 - val_auroc: 0.4991\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 1s 389ms/step - loss: 0.4367 - accuracy: 0.7768 - auroc: 0.8260 - val_loss: 0.7429 - val_accuracy: 0.4947 - val_auroc: 0.4926\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4421 - accuracy: 0.7716 - auroc: 0.8222 - val_loss: 0.7325 - val_accuracy: 0.4825 - val_auroc: 0.4866\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4405 - accuracy: 0.7737 - auroc: 0.8244 - val_loss: 0.7803 - val_accuracy: 0.5509 - val_auroc: 0.4889\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4347 - accuracy: 0.7632 - auroc: 0.8198 - val_loss: 0.7456 - val_accuracy: 0.5123 - val_auroc: 0.4867\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 1s 409ms/step - loss: 0.4410 - accuracy: 0.7716 - auroc: 0.8229 - val_loss: 0.7388 - val_accuracy: 0.4860 - val_auroc: 0.4833\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4385 - accuracy: 0.7695 - auroc: 0.8235 - val_loss: 0.7628 - val_accuracy: 0.4860 - val_auroc: 0.4849\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4380 - accuracy: 0.7758 - auroc: 0.8271 - val_loss: 0.7823 - val_accuracy: 0.4895 - val_auroc: 0.4934\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4413 - accuracy: 0.7737 - auroc: 0.8208 - val_loss: 0.7542 - val_accuracy: 0.4737 - val_auroc: 0.4850\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4364 - accuracy: 0.7747 - auroc: 0.8268 - val_loss: 0.7519 - val_accuracy: 0.4684 - val_auroc: 0.4886\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 1s 408ms/step - loss: 0.4313 - accuracy: 0.7768 - auroc: 0.8293 - val_loss: 0.7583 - val_accuracy: 0.4649 - val_auroc: 0.4889\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4276 - accuracy: 0.7789 - auroc: 0.8414 - val_loss: 0.7474 - val_accuracy: 0.4596 - val_auroc: 0.4856\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4381 - accuracy: 0.7789 - auroc: 0.8252 - val_loss: 0.7721 - val_accuracy: 0.4561 - val_auroc: 0.4862\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.4348 - accuracy: 0.7789 - auroc: 0.8302 - val_loss: 0.7646 - val_accuracy: 0.4544 - val_auroc: 0.4848\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 1s 375ms/step - loss: 0.4343 - accuracy: 0.7747 - auroc: 0.8280 - val_loss: 0.7616 - val_accuracy: 0.4614 - val_auroc: 0.4879\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4334 - accuracy: 0.7758 - auroc: 0.8346 - val_loss: 0.7550 - val_accuracy: 0.4614 - val_auroc: 0.4927\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.4369 - accuracy: 0.7768 - auroc: 0.8256 - val_loss: 0.7724 - val_accuracy: 0.4667 - val_auroc: 0.4882\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 1s 366ms/step - loss: 0.4305 - accuracy: 0.7779 - auroc: 0.8256 - val_loss: 0.7449 - val_accuracy: 0.4579 - val_auroc: 0.4827\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4372 - accuracy: 0.7768 - auroc: 0.8279 - val_loss: 0.7681 - val_accuracy: 0.4684 - val_auroc: 0.4873\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4386 - accuracy: 0.7758 - auroc: 0.8358 - val_loss: 0.7769 - val_accuracy: 0.4702 - val_auroc: 0.4894\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4304 - accuracy: 0.7800 - auroc: 0.8307 - val_loss: 0.7525 - val_accuracy: 0.4596 - val_auroc: 0.4911\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 1s 400ms/step - loss: 0.4313 - accuracy: 0.7821 - auroc: 0.8296 - val_loss: 0.7470 - val_accuracy: 0.4579 - val_auroc: 0.4960\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4314 - accuracy: 0.7832 - auroc: 0.8356 - val_loss: 0.7521 - val_accuracy: 0.4895 - val_auroc: 0.4908\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4357 - accuracy: 0.7705 - auroc: 0.8214 - val_loss: 0.7563 - val_accuracy: 0.4825 - val_auroc: 0.4853\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4404 - accuracy: 0.7821 - auroc: 0.8244 - val_loss: 0.7484 - val_accuracy: 0.4544 - val_auroc: 0.4744\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4400 - accuracy: 0.7779 - auroc: 0.8243 - val_loss: 0.7814 - val_accuracy: 0.4789 - val_auroc: 0.4716\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4299 - accuracy: 0.7789 - auroc: 0.8276 - val_loss: 0.7937 - val_accuracy: 0.4702 - val_auroc: 0.4809\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 1s 367ms/step - loss: 0.4308 - accuracy: 0.7768 - auroc: 0.8228 - val_loss: 0.7694 - val_accuracy: 0.4614 - val_auroc: 0.4832\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4321 - accuracy: 0.7768 - auroc: 0.8315 - val_loss: 0.7548 - val_accuracy: 0.4456 - val_auroc: 0.4804\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4360 - accuracy: 0.7800 - auroc: 0.8321 - val_loss: 0.7875 - val_accuracy: 0.4667 - val_auroc: 0.4793\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4289 - accuracy: 0.7842 - auroc: 0.8236 - val_loss: 0.7712 - val_accuracy: 0.4509 - val_auroc: 0.4895\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 1s 354ms/step - loss: 0.4249 - accuracy: 0.7832 - auroc: 0.8320 - val_loss: 0.7513 - val_accuracy: 0.4333 - val_auroc: 0.4928\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4384 - accuracy: 0.7716 - auroc: 0.8216 - val_loss: 0.7642 - val_accuracy: 0.4368 - val_auroc: 0.5019\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 1s 363ms/step - loss: 0.4385 - accuracy: 0.7747 - auroc: 0.8257 - val_loss: 0.7592 - val_accuracy: 0.4368 - val_auroc: 0.4751\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.4316 - accuracy: 0.7716 - auroc: 0.8231 - val_loss: 0.7863 - val_accuracy: 0.4632 - val_auroc: 0.4754\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4279 - accuracy: 0.7726 - auroc: 0.8265 - val_loss: 0.8019 - val_accuracy: 0.4825 - val_auroc: 0.4787\n",
      "Epoch 84/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4391 - accuracy: 0.7726 - auroc: 0.8256 - val_loss: 0.7782 - val_accuracy: 0.4842 - val_auroc: 0.4828\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4301 - accuracy: 0.7779 - auroc: 0.8364 - val_loss: 0.7541 - val_accuracy: 0.4772 - val_auroc: 0.4868\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 1s 379ms/step - loss: 0.4322 - accuracy: 0.7726 - auroc: 0.8329 - val_loss: 0.7717 - val_accuracy: 0.4807 - val_auroc: 0.4850\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4402 - accuracy: 0.7737 - auroc: 0.8298 - val_loss: 0.7782 - val_accuracy: 0.4860 - val_auroc: 0.4878\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4357 - accuracy: 0.7758 - auroc: 0.8180 - val_loss: 0.7529 - val_accuracy: 0.4614 - val_auroc: 0.4890\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4358 - accuracy: 0.7779 - auroc: 0.8248 - val_loss: 0.7543 - val_accuracy: 0.4596 - val_auroc: 0.4894\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4321 - accuracy: 0.7800 - auroc: 0.8332 - val_loss: 0.7796 - val_accuracy: 0.4667 - val_auroc: 0.4889\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 1s 402ms/step - loss: 0.4317 - accuracy: 0.7779 - auroc: 0.8287 - val_loss: 0.7680 - val_accuracy: 0.4667 - val_auroc: 0.4799\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4352 - accuracy: 0.7789 - auroc: 0.8214 - val_loss: 0.7503 - val_accuracy: 0.4509 - val_auroc: 0.4849\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.4357 - accuracy: 0.7800 - auroc: 0.8243 - val_loss: 0.7655 - val_accuracy: 0.4649 - val_auroc: 0.4908\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4243 - accuracy: 0.7779 - auroc: 0.8316 - val_loss: 0.7625 - val_accuracy: 0.4509 - val_auroc: 0.4900\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4262 - accuracy: 0.7768 - auroc: 0.8386 - val_loss: 0.7787 - val_accuracy: 0.4561 - val_auroc: 0.4849\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 1s 368ms/step - loss: 0.4311 - accuracy: 0.7789 - auroc: 0.8368 - val_loss: 0.7754 - val_accuracy: 0.4544 - val_auroc: 0.4942\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4276 - accuracy: 0.7800 - auroc: 0.8255 - val_loss: 0.7626 - val_accuracy: 0.4456 - val_auroc: 0.5000\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4293 - accuracy: 0.7832 - auroc: 0.8264 - val_loss: 0.7553 - val_accuracy: 0.4439 - val_auroc: 0.5034\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 1s 409ms/step - loss: 0.4285 - accuracy: 0.7821 - auroc: 0.8183 - val_loss: 0.7638 - val_accuracy: 0.4456 - val_auroc: 0.4852\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4307 - accuracy: 0.7800 - auroc: 0.8318 - val_loss: 0.7550 - val_accuracy: 0.4439 - val_auroc: 0.5074\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4298 - accuracy: 0.7789 - auroc: 0.8254 - val_loss: 0.7592 - val_accuracy: 0.4526 - val_auroc: 0.5032\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 1s 389ms/step - loss: 0.4317 - accuracy: 0.7789 - auroc: 0.8215 - val_loss: 0.7707 - val_accuracy: 0.4649 - val_auroc: 0.5095\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4281 - accuracy: 0.7789 - auroc: 0.8303 - val_loss: 0.7708 - val_accuracy: 0.4737 - val_auroc: 0.5065\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4308 - accuracy: 0.7789 - auroc: 0.8314 - val_loss: 0.7624 - val_accuracy: 0.4702 - val_auroc: 0.4998\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4273 - accuracy: 0.7821 - auroc: 0.8371 - val_loss: 0.7759 - val_accuracy: 0.4807 - val_auroc: 0.4954\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 1s 398ms/step - loss: 0.4313 - accuracy: 0.7821 - auroc: 0.8288 - val_loss: 0.7654 - val_accuracy: 0.4737 - val_auroc: 0.4941\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4316 - accuracy: 0.7842 - auroc: 0.8271 - val_loss: 0.7622 - val_accuracy: 0.4702 - val_auroc: 0.4996\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4268 - accuracy: 0.7821 - auroc: 0.8285 - val_loss: 0.7715 - val_accuracy: 0.4754 - val_auroc: 0.5008\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4300 - accuracy: 0.7800 - auroc: 0.8335 - val_loss: 0.7575 - val_accuracy: 0.4561 - val_auroc: 0.5003\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 1s 401ms/step - loss: 0.4251 - accuracy: 0.7863 - auroc: 0.8376 - val_loss: 0.7630 - val_accuracy: 0.4561 - val_auroc: 0.4973\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4234 - accuracy: 0.7811 - auroc: 0.8302 - val_loss: 0.7731 - val_accuracy: 0.4667 - val_auroc: 0.4968\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4323 - accuracy: 0.7821 - auroc: 0.8311 - val_loss: 0.7558 - val_accuracy: 0.4439 - val_auroc: 0.5019\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 1s 408ms/step - loss: 0.4308 - accuracy: 0.7821 - auroc: 0.8169 - val_loss: 0.7728 - val_accuracy: 0.4561 - val_auroc: 0.5070\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4251 - accuracy: 0.7789 - auroc: 0.8288 - val_loss: 0.7543 - val_accuracy: 0.4421 - val_auroc: 0.5065\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4254 - accuracy: 0.7789 - auroc: 0.8429 - val_loss: 0.7579 - val_accuracy: 0.4421 - val_auroc: 0.5142\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4188 - accuracy: 0.7800 - auroc: 0.8410 - val_loss: 0.7742 - val_accuracy: 0.4614 - val_auroc: 0.5156\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 1s 357ms/step - loss: 0.4277 - accuracy: 0.7811 - auroc: 0.8284 - val_loss: 0.7601 - val_accuracy: 0.4404 - val_auroc: 0.5079\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4254 - accuracy: 0.7821 - auroc: 0.8393 - val_loss: 0.7658 - val_accuracy: 0.4439 - val_auroc: 0.5043\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4220 - accuracy: 0.7811 - auroc: 0.8343 - val_loss: 0.7822 - val_accuracy: 0.4386 - val_auroc: 0.4963\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4258 - accuracy: 0.7863 - auroc: 0.8387 - val_loss: 0.7635 - val_accuracy: 0.4263 - val_auroc: 0.5065\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 1s 406ms/step - loss: 0.4230 - accuracy: 0.7811 - auroc: 0.8372 - val_loss: 0.7811 - val_accuracy: 0.4509 - val_auroc: 0.5017\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4283 - accuracy: 0.7779 - auroc: 0.8330 - val_loss: 0.7650 - val_accuracy: 0.4333 - val_auroc: 0.4927\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4281 - accuracy: 0.7832 - auroc: 0.8327 - val_loss: 0.7712 - val_accuracy: 0.4368 - val_auroc: 0.4920\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49200907349586487\n",
      "0.4890597442680776\n"
     ]
    }
   ],
   "source": [
    "x_input = Input(shape=train_pos_matrix.shape[1])\n",
    "x_output = Embedding(input_dim = num_pos,\n",
    "                    output_dim = 8)(x_input)\n",
    "x_output = Bidirectional(LSTM(25, return_sequences = True))(x_output)\n",
    "x_output = Bidirectional(LSTM(25))(x_output)\n",
    "x_output = Dropout(0.3)(x_output)\n",
    "x_output = Dense(50,activation='relu')(x_output)\n",
    "x_output = Dropout(0.3)(x_output)\n",
    "x_output = Dense(20,activation = 'relu')(x_output) \n",
    "x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "model.summary()\n",
    "\n",
    "patience = 50\n",
    "batch_size = 256\n",
    "epochs = 1000\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_auroc', patience=patience)]\n",
    "history = model.fit(train_pos_matrix,y_train,\n",
    "                             validation_data = (val_pos_matrix,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks,\n",
    "                             verbose = 1)\n",
    "\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "y_pred = model.predict(test_pos_matrix,\n",
    "                       batch_size = batch_size)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    pos_label=1,\n",
    ")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=train_reduced_pos_matrix.shape[1])\n",
    "x_output = Embedding(input_dim = num_reduced_pos,\n",
    "                    output_dim = 8)(x_input)\n",
    "x_output = Bidirectional(LSTM(25, return_sequences = True),input_shape=input_shape)(x_output)\n",
    "x_output = Bidirectional(LSTM(25))(x_output)\n",
    "x_output = Dropout(0.3)(x_output)\n",
    "x_output = Dense(50,activation='relu')(x_output)\n",
    "x_output = Dropout(0.3)(x_output)\n",
    "x_output = Dense(20,activation = 'relu')(x_output) \n",
    "x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "model.summary()\n",
    "\n",
    "patience = 50\n",
    "batch_size = 256\n",
    "epochs = 1000\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_auroc', patience=patience)]\n",
    "history = model.fit(train_reduced_pos_matrix,y_train,\n",
    "                             validation_data = (val_reduced_pos_matrix,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks,\n",
    "                             verbose = 0)\n",
    "\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "y_pred = model.predict(test_reduced_pos_matrix,\n",
    "                       batch_size = batch_size)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    pos_label=1,\n",
    ")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X Y input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_inputs = x_train_all[:,:,-2]\n",
    "#y_train_inputs = x_train_all[:,:,-1]\n",
    "train_inputs   = x_train_all[:,:,[-2,-1]]\n",
    "val_inputs     = train_inputs[val_idx]\n",
    "train_inputs   = train_inputs[train_idx]\n",
    "#x_test_inputs  = x_test_all[:,:,-2]\n",
    "#y_test_inputs  = x_test_all[:,:,-2]\n",
    "test_inputs    = x_test_all[:,:,[-2,-1]]\n",
    "\n",
    "x_input = Input(shape=(train_inputs.shape[1],train_inputs.shape[2]))\n",
    "x_avg = GlobalAveragePooling1D()(x_input)\n",
    "x_max = GlobalMaxPool1D()(x_input)\n",
    "x_output = Concatenate()([x_avg,x_max])\n",
    "#x_output = Dense(256,activation='relu')(x_output)\n",
    "#x_output = Dense(128,activation='relu')(x_output)\n",
    "#x_output = Dropout(0.2)(x_output)\n",
    "#x_output = Dense(64,activation='relu')(x_output)\n",
    "#x_output = Dense(32,activation='relu')(x_output)\n",
    "#x_output = Dense(16,activation='relu')(x_output)\n",
    "x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "model.summary()\n",
    "\n",
    "patience = 50\n",
    "batch_size = 256\n",
    "epochs = 1000\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_auroc', patience=patience)]\n",
    "history = model.fit(train_inputs,y_train,\n",
    "                             validation_data = (val_inputs,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks,\n",
    "                             verbose = 0)\n",
    "\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "y_pred = model.predict(test_inputs,\n",
    "                       batch_size = batch_size)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    pos_label=1,\n",
    ")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_inputs = x_train_all[:,:,-2]\n",
    "#y_train_inputs = x_train_all[:,:,-1]\n",
    "train_inputs   = x_train_all[:,:,[-2,-1]]\n",
    "val_inputs     = train_inputs[val_idx]\n",
    "train_inputs   = train_inputs[train_idx]\n",
    "#x_test_inputs  = x_test_all[:,:,-2]\n",
    "#y_test_inputs  = x_test_all[:,:,-2]\n",
    "test_inputs    = x_test_all[:,:,[-2,-1]]\n",
    "\n",
    "x_input = Input(shape=(train_inputs.shape[1],train_inputs.shape[2]))\n",
    "x = Conv1D(32, 4, activation='gelu')(x_input)\n",
    "x = AveragePooling1D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(64, 2, activation='gelu')(x)\n",
    "x = AveragePooling1D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "#x = Conv1D(64, 4, activation='gelu')(x)\n",
    "#x = AveragePooling1D(pool_size=2)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = Flatten()(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "#x = Dense(1024,activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Dense(512,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32,activation='relu')(x)\n",
    "x_output = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "model.summary()\n",
    "\n",
    "patience = 5000\n",
    "batch_size = 256\n",
    "epochs = 1000\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_auroc', patience=patience)]\n",
    "history = model.fit(train_inputs,y_train,\n",
    "                             validation_data = (val_inputs,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks,\n",
    "                             verbose = 0)\n",
    "\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "y_pred = model.predict(test_inputs,\n",
    "                       batch_size = batch_size)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    pos_label=1,\n",
    ")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS 1DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=train_pos_matrix.shape[1])\n",
    "x_emb = Embedding(input_dim = num_pos,\n",
    "                    output_dim = 32)(x_input)\n",
    "x = Conv1D(64, 3, activation='gelu')(x_emb)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Flatten()(x)\n",
    "x_avg = GlobalAveragePooling1D()(x_emb)\n",
    "concat = Concatenate()([x,x_avg])\n",
    "x_output = Dense(32,activation='relu')(concat)\n",
    "x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "model.summary()\n",
    "\n",
    "patience = 50\n",
    "batch_size = 256\n",
    "epochs = 1000\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_auroc', patience=patience)]\n",
    "history = model.fit(train_pos_matrix,y_train,\n",
    "                             validation_data = (val_pos_matrix,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks,\n",
    "                             verbose = 0)\n",
    "\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "y_pred = model.predict(test_pos_matrix,\n",
    "                       batch_size = batch_size)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    pos_label=1,\n",
    ")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=train_ent_matrix.shape[1])\n",
    "x_output = Embedding(input_dim = num_ent,\n",
    "                    output_dim = 64)(x_input)\n",
    "x_avg = GlobalAveragePooling1D()(x_output)\n",
    "x_max = GlobalMaxPool1D()(x_output)\n",
    "x_output = Concatenate()([x_avg,x_max])\n",
    "#x_output = Dense(256,activation='relu')(x_output)\n",
    "#x_output = Dense(128,activation='relu')(x_output)\n",
    "x_output = Dense(64,activation='relu')(x_output)\n",
    "x_output = Dense(32,activation='relu')(x_output)\n",
    "x_output = Dense(16,activation='relu')(x_output)\n",
    "x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "model.summary()\n",
    "\n",
    "patience = 50\n",
    "batch_size = 256\n",
    "epochs = 1000\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_auroc', patience=patience)]\n",
    "history = model.fit(train_ent_matrix,y_train,\n",
    "                             validation_data = (val_ent_matrix,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks,\n",
    "                             verbose = 0)\n",
    "\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "print(history.history['val_auroc'][-1])\n",
    "\n",
    "y_pred = model.predict(test_ent_matrix,\n",
    "                       batch_size = batch_size)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    pos_label=1,\n",
    ")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drop_out_rates = [0.1,0.2,0.3,0.4,0.5]\n",
    "for drop_outs in drop_out_rates:\n",
    "    x_input = Input(shape=num_features)\n",
    "    x_num = Dense(256,activation='relu')(x_input)\n",
    "    x_num = Dropout(drop_outs)(x_num)\n",
    "    x_num = Dense(128,activation='relu')(x_num)\n",
    "    x_num = Dropout(drop_outs)(x_num)\n",
    "    x_num = Dense(64,activation='relu')(x_num)\n",
    "    x_num = Dropout(drop_outs)(x_num)\n",
    "    x_num = Dense(32,activation='relu')(x_num)\n",
    "    x_output = Dense(1,activation='sigmoid')(x_num)\n",
    "    model = Model(inputs=x_input, outputs=x_output)\n",
    "    opt = Adam()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "    model.summary()\n",
    "\n",
    "    patience = 50\n",
    "    batch_size = 256\n",
    "    epochs = 1000\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_val_scaled = scaler.transform(x_val)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_auroc', patience=patience)]\n",
    "    history = model.fit(x_train_scaled,y_train,\n",
    "                                 validation_data = (x_val_scaled,y_val),\n",
    "                                 batch_size = batch_size,\n",
    "                                 epochs = epochs,\n",
    "                                 callbacks = callbacks,\n",
    "                                 verbose = 0)\n",
    "\n",
    "    plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "    plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(history.history['val_auroc'][-1])\n",
    "\n",
    "    y_pred = model.predict(x_test_scaled,\n",
    "                           batch_size = batch_size)\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        pos_label=1,\n",
    "    )\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(x_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(history.history['val_auroc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=train_ent_matrix.shape[1])\n",
    "x_output = Embedding(input_dim = max_pos_len,\n",
    "                    output_dim = 64)(x_input)\n",
    "x_output = Dense(32,activation='relu')(x_output)\n",
    "x_output = GlobalAveragePooling1D()(x_output)\n",
    "x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patience = 10\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "history = model.fit(train_ent_matrix,y_train,\n",
    "                             validation_data = (val_ent_matrix,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=x_train.shape[1])\n",
    "x_output = Dense(256,activation='relu')(x_input)\n",
    "x_output = Dense(128,activation='relu')(x_output)\n",
    "x_output = Dense(64,activation='relu')(x_output)\n",
    "x_output = Dense(1,activation='sigmoid')(x_output)\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', auroc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patience = 10\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "history = model.fit(x_train,y_train,\n",
    "                             validation_data = (x_val,y_val),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs = epochs,\n",
    "                             callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['val_auroc'],label='validation')\n",
    "plt.plot(np.arange(len(history.history['val_auroc'])),history.history['auroc'],label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train,return_counts = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
