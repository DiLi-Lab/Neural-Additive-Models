{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import rf_feature_extraction as rf_feature_extraction\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Plotting import plotting_utils as plotting_utils\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## global variable\n",
    "datanorm = True\n",
    "datacols = ['CURRENT_FIX_X', 'CURRENT_FIX_Y', 'CURRENT_FIX_PUPIL', 'CURRENT_FIX_DURATION']\n",
    "\n",
    "# delta = 10 # size of window based on the middle point\n",
    "# step =  2*delta+1 #if you want no overlap: 2*delta+1 # size of step in window extraction\n",
    "\n",
    "datasplit = 'subject'\n",
    "\n",
    "labelcols = ['subj', 'book',\n",
    "            'acc_level', 'subj_acc_level', \n",
    "            'confidence', 'difficulty', 'familiarity', 'recognition', \n",
    "            'interest', 'pressured', 'sleepiness', 'sleephours',\n",
    "            'sex', 'native']\n",
    "\n",
    "pred_variable = 'subj_acc_level'\n",
    "\n",
    "modeltype = 'cnn'\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1000\n",
    "\n",
    "# data path\n",
    "file_fixdata = '../SB-SAT/fixation/18sat_fixfinal.csv'\n",
    "file_trialdata = '../SB-SAT/fixation/18sat_trialfinal.csv'\n",
    "file_labels = '../SB-SAT/fixation/18sat_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subj       book  acc_level  subj_acc_level  confidence  difficulty  \\\n",
      "0  msd001    dickens          2               3           2           0   \n",
      "1  msd001    flytrap          3               3           2           1   \n",
      "2  msd001     genome          3               3           1           0   \n",
      "3  msd001  northpole          3               3           1           1   \n",
      "\n",
      "   familiarity  recognition  interest  pressured  sleepiness  sleephours sex  \\\n",
      "0            1            0         2          0           1           2   F   \n",
      "1            2            0         2          1           1           2   F   \n",
      "2            1            0         2          1           2           2   F   \n",
      "3            1            0         1          1           2           2   F   \n",
      "\n",
      "   native  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n"
     ]
    }
   ],
   "source": [
    "## score file load\n",
    "sc = pd.read_csv(file_labels)\n",
    "\n",
    "## select label columns\n",
    "sc = sc[labelcols]\n",
    "print(sc.loc[sc.subj == 'msd001'])\n",
    "## cut/replace values\n",
    "sc['sex'] = sc['sex'].replace(['F', 'M'], [1, 0])\n",
    "binarycols = ('recognition', 'sex', 'native')\n",
    "subsetcols = [c for c in labelcols if c not in binarycols]\n",
    "sc[subsetcols] = sc[subsetcols].replace([0,1,2,3], [0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>book</th>\n",
       "      <th>acc_level</th>\n",
       "      <th>subj_acc_level</th>\n",
       "      <th>confidence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>recognition</th>\n",
       "      <th>interest</th>\n",
       "      <th>pressured</th>\n",
       "      <th>sleepiness</th>\n",
       "      <th>sleephours</th>\n",
       "      <th>sex</th>\n",
       "      <th>native</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msd001</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>msd001</td>\n",
       "      <td>flytrap</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>msd001</td>\n",
       "      <td>genome</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>msd001</td>\n",
       "      <td>northpole</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>msd002</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj       book  acc_level  subj_acc_level  confidence  difficulty  \\\n",
       "0  msd001    dickens          1               1           1           0   \n",
       "1  msd001    flytrap          1               1           1           0   \n",
       "2  msd001     genome          1               1           0           0   \n",
       "3  msd001  northpole          1               1           0           0   \n",
       "4  msd002    dickens          1               0           1           0   \n",
       "\n",
       "   familiarity  recognition  interest  pressured  sleepiness  sleephours  sex  \\\n",
       "0            0            0         1          0           0           1    1   \n",
       "1            1            0         1          0           0           1    1   \n",
       "2            0            0         1          0           1           1    1   \n",
       "3            0            0         0          0           1           1    1   \n",
       "4            0            0         1          0           0           1    0   \n",
       "\n",
       "   native  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORDING_SESSION_LABEL</th>\n",
       "      <th>TRIAL_INDEX</th>\n",
       "      <th>CURRENT_FIX_X</th>\n",
       "      <th>CURRENT_FIX_Y</th>\n",
       "      <th>CURRENT_FIX_PUPIL</th>\n",
       "      <th>CURRENT_FIX_DURATION</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_ID</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_LABEL</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_PIXEL_AREA</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_RUN_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Trial_Recycled_</th>\n",
       "      <th>total_page</th>\n",
       "      <th>type</th>\n",
       "      <th>book_name</th>\n",
       "      <th>book</th>\n",
       "      <th>page</th>\n",
       "      <th>RT</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>page_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msd001</td>\n",
       "      <td>1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>125.4</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25094.538413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>msd001</td>\n",
       "      <td>1</td>\n",
       "      <td>348.7</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>26</td>\n",
       "      <td>24.0</td>\n",
       "      <td>long</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25094.538413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>msd001</td>\n",
       "      <td>1</td>\n",
       "      <td>630.5</td>\n",
       "      <td>400.3</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>216</td>\n",
       "      <td>72.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>3136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25094.538413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>msd001</td>\n",
       "      <td>1</td>\n",
       "      <td>492.0</td>\n",
       "      <td>400.2</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>125</td>\n",
       "      <td>69.0</td>\n",
       "      <td>boundless</td>\n",
       "      <td>7488.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25094.538413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>msd001</td>\n",
       "      <td>1</td>\n",
       "      <td>526.6</td>\n",
       "      <td>390.5</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>486</td>\n",
       "      <td>70.0</td>\n",
       "      <td>world,</td>\n",
       "      <td>4992.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25094.538413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RECORDING_SESSION_LABEL  TRIAL_INDEX  CURRENT_FIX_X  CURRENT_FIX_Y  \\\n",
       "0                  msd001            1           59.8          125.4   \n",
       "1                  msd001            1          348.7          182.0   \n",
       "2                  msd001            1          630.5          400.3   \n",
       "3                  msd001            1          492.0          400.2   \n",
       "4                  msd001            1          526.6          390.5   \n",
       "\n",
       "   CURRENT_FIX_PUPIL  CURRENT_FIX_DURATION  CURRENT_FIX_INTEREST_AREA_ID  \\\n",
       "0             1430.0                    22                           NaN   \n",
       "1             1375.0                    26                          24.0   \n",
       "2             1365.0                   216                          72.0   \n",
       "3             1440.0                   125                          69.0   \n",
       "4             1265.0                   486                          70.0   \n",
       "\n",
       "  CURRENT_FIX_INTEREST_AREA_LABEL  CURRENT_FIX_INTEREST_AREA_PIXEL_AREA  \\\n",
       "0                             NaN                                   NaN   \n",
       "1                            long                                3520.0   \n",
       "2                            safe                                3136.0   \n",
       "3                       boundless                                7488.0   \n",
       "4                          world,                                4992.0   \n",
       "\n",
       "   CURRENT_FIX_INTEREST_AREA_RUN_ID  ...  Trial_Recycled_ total_page     type  \\\n",
       "0                               NaN  ...             True          5  reading   \n",
       "1                               1.0  ...             True          5  reading   \n",
       "2                               1.0  ...             True          5  reading   \n",
       "3                               1.0  ...             True          5  reading   \n",
       "4                               1.0  ...             True          5  reading   \n",
       "\n",
       "   book_name  book page            RT answer  correct_answer  \\\n",
       "0    dickens     1    1  25094.538413      1             -99   \n",
       "1    dickens     1    1  25094.538413      1             -99   \n",
       "2    dickens     1    1  25094.538413      1             -99   \n",
       "3    dickens     1    1  25094.538413      1             -99   \n",
       "4    dickens     1    1  25094.538413      1             -99   \n",
       "\n",
       "           page_name  \n",
       "0  reading-dickens-1  \n",
       "1  reading-dickens-1  \n",
       "2  reading-dickens-1  \n",
       "3  reading-dickens-1  \n",
       "4  reading-dickens-1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fixation data load\n",
    "fd = pd.read_csv(file_fixdata)\n",
    "fd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixData = fd.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ce52bc43aa47b3919c21289ecc05a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=95.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "users = fixData.RECORDING_SESSION_LABEL.unique().tolist()\n",
    "books = fixData.book_name.unique().tolist()\n",
    "pages = fixData.page.unique().tolist()\n",
    "data_arr = []#np.empty((0, fixData.shape[1]))\n",
    "label_arr = np.empty((0, sc.shape[1]))\n",
    "for user in tqdm(users):\n",
    "    for book in books:\n",
    "        tmp_label = sc.loc[sc.subj == user].loc[sc.book == book]\n",
    "        for page in pages:\n",
    "            tmp_df = fixData.loc[fixData.RECORDING_SESSION_LABEL == user].loc[fixData.book_name == book].loc[fixData.page == page]\n",
    "            #XXXXXXX\n",
    "            tmp_len = len(tmp_df)\n",
    "            if tmp_len > 0:\n",
    "                data_arr.append(tmp_df)\n",
    "                label_arr = np.vstack([label_arr, tmp_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4940,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-df72452750c2>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  data_arr_np = np.array(data_arr)\n"
     ]
    }
   ],
   "source": [
    "data_arr_np = np.array(data_arr)\n",
    "print(data_arr_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['(FIN)', '(forms', '(it', ..., '\\x93If', '\\x93milking',\n",
       "        '\\x93pharming,\\x94'], dtype='<U18'),\n",
       " array([382, 154,  37, ...,  48, 185, 241]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(fixData['CURRENT_FIX_INTEREST_AREA_LABEL'],dtype=np.str), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['DOWN', 'LEFT', 'RIGHT', 'UP', 'nan'], dtype='<U5'),\n",
       " array([ 14976, 139047, 270115,  17011,  22415]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(fixData['PREVIOUS_SAC_DIRECTION'],dtype=np.str), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4940/4940 [00:34<00:00, 144.29it/s]\n",
      "100%|██████████| 4940/4940 [00:00<00:00, 11002.99it/s]\n",
      "100%|██████████| 4940/4940 [01:59<00:00, 41.46it/s]\n"
     ]
    }
   ],
   "source": [
    "data_arr_rf, feature_names_rf = rf_feature_extraction.get_combined_features(data_arr_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4940, 317)\n"
     ]
    }
   ],
   "source": [
    "print(data_arr_rf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CURRENT_FIX_X_mean',\n",
       " 'CURRENT_FIX_X_std',\n",
       " 'CURRENT_FIX_X_median',\n",
       " 'CURRENT_FIX_X_skew',\n",
       " 'CURRENT_FIX_X_kurtosis',\n",
       " 'CURRENT_FIX_Y_mean',\n",
       " 'CURRENT_FIX_Y_std',\n",
       " 'CURRENT_FIX_Y_median',\n",
       " 'CURRENT_FIX_Y_skew',\n",
       " 'CURRENT_FIX_Y_kurtosis',\n",
       " 'CURRENT_FIX_PUPIL_mean',\n",
       " 'CURRENT_FIX_PUPIL_std',\n",
       " 'CURRENT_FIX_PUPIL_median',\n",
       " 'CURRENT_FIX_PUPIL_skew',\n",
       " 'CURRENT_FIX_PUPIL_kurtosis',\n",
       " 'CURRENT_FIX_DURATION_mean',\n",
       " 'CURRENT_FIX_DURATION_std',\n",
       " 'CURRENT_FIX_DURATION_median',\n",
       " 'CURRENT_FIX_DURATION_skew',\n",
       " 'CURRENT_FIX_DURATION_kurtosis',\n",
       " 'CURRENT_FIX_INTEREST_AREA_ID_mean',\n",
       " 'CURRENT_FIX_INTEREST_AREA_ID_std',\n",
       " 'CURRENT_FIX_INTEREST_AREA_ID_median',\n",
       " 'CURRENT_FIX_INTEREST_AREA_ID_skew',\n",
       " 'CURRENT_FIX_INTEREST_AREA_ID_kurtosis',\n",
       " 'CURRENT_FIX_INTEREST_AREA_PIXEL_AREA_mean',\n",
       " 'CURRENT_FIX_INTEREST_AREA_PIXEL_AREA_std',\n",
       " 'CURRENT_FIX_INTEREST_AREA_PIXEL_AREA_median',\n",
       " 'CURRENT_FIX_INTEREST_AREA_PIXEL_AREA_skew',\n",
       " 'CURRENT_FIX_INTEREST_AREA_PIXEL_AREA_kurtosis',\n",
       " 'CURRENT_FIX_INTEREST_AREA_RUN_ID_mean',\n",
       " 'CURRENT_FIX_INTEREST_AREA_RUN_ID_std',\n",
       " 'CURRENT_FIX_INTEREST_AREA_RUN_ID_median',\n",
       " 'CURRENT_FIX_INTEREST_AREA_RUN_ID_skew',\n",
       " 'CURRENT_FIX_INTEREST_AREA_RUN_ID_kurtosis',\n",
       " 'CURRENT_FIX_INTEREST_AREA_DWELL_TIME_mean',\n",
       " 'CURRENT_FIX_INTEREST_AREA_DWELL_TIME_std',\n",
       " 'CURRENT_FIX_INTEREST_AREA_DWELL_TIME_median',\n",
       " 'CURRENT_FIX_INTEREST_AREA_DWELL_TIME_skew',\n",
       " 'CURRENT_FIX_INTEREST_AREA_DWELL_TIME_kurtosis',\n",
       " 'PREVIOUS_SAC_ANGLE_mean',\n",
       " 'PREVIOUS_SAC_ANGLE_std',\n",
       " 'PREVIOUS_SAC_ANGLE_median',\n",
       " 'PREVIOUS_SAC_ANGLE_skew',\n",
       " 'PREVIOUS_SAC_ANGLE_kurtosis',\n",
       " 'PREVIOUS_SAC_AMPLITUDE_mean',\n",
       " 'PREVIOUS_SAC_AMPLITUDE_std',\n",
       " 'PREVIOUS_SAC_AMPLITUDE_median',\n",
       " 'PREVIOUS_SAC_AMPLITUDE_skew',\n",
       " 'PREVIOUS_SAC_AMPLITUDE_kurtosis',\n",
       " 'PREVIOUS_SAC_AVG_VELOCITY_mean',\n",
       " 'PREVIOUS_SAC_AVG_VELOCITY_std',\n",
       " 'PREVIOUS_SAC_AVG_VELOCITY_median',\n",
       " 'PREVIOUS_SAC_AVG_VELOCITY_skew',\n",
       " 'PREVIOUS_SAC_AVG_VELOCITY_kurtosis',\n",
       " 'PREVIOUS_SAC_CONTAINS_BLINK_mean',\n",
       " 'PREVIOUS_SAC_CONTAINS_BLINK_std',\n",
       " 'PREVIOUS_SAC_CONTAINS_BLINK_median',\n",
       " 'PREVIOUS_SAC_CONTAINS_BLINK_skew',\n",
       " 'PREVIOUS_SAC_CONTAINS_BLINK_kurtosis',\n",
       " 'PREVIOUS_SAC_BLINK_DURATION_mean',\n",
       " 'PREVIOUS_SAC_BLINK_DURATION_std',\n",
       " 'PREVIOUS_SAC_BLINK_DURATION_median',\n",
       " 'PREVIOUS_SAC_BLINK_DURATION_skew',\n",
       " 'PREVIOUS_SAC_BLINK_DURATION_kurtosis',\n",
       " 'PREVIOUS_SAC_DIRECTION_DOWN_count',\n",
       " 'PREVIOUS_SAC_DIRECTION_DOWN_frac',\n",
       " 'PREVIOUS_SAC_DIRECTION_LEFT_count',\n",
       " 'PREVIOUS_SAC_DIRECTION_LEFT_frac',\n",
       " 'PREVIOUS_SAC_DIRECTION_RIGHT_count',\n",
       " 'PREVIOUS_SAC_DIRECTION_RIGHT_frac',\n",
       " 'PREVIOUS_SAC_DIRECTION_UP_count',\n",
       " 'PREVIOUS_SAC_DIRECTION_UP_frac',\n",
       " 'lexical_entity_count_',\n",
       " 'lexical_entity_frac_',\n",
       " 'lexical_entity_count_DATE',\n",
       " 'lexical_entity_frac_DATE',\n",
       " 'lexical_entity_count_QUANTITY',\n",
       " 'lexical_entity_frac_QUANTITY',\n",
       " 'lexical_entity_count_ORG',\n",
       " 'lexical_entity_frac_ORG',\n",
       " 'lexical_entity_count_GPE',\n",
       " 'lexical_entity_frac_GPE',\n",
       " 'lexical_entity_count_NORP',\n",
       " 'lexical_entity_frac_NORP',\n",
       " 'lexical_entity_count_PERSON',\n",
       " 'lexical_entity_frac_PERSON',\n",
       " 'lexical_entity_count_TIME',\n",
       " 'lexical_entity_frac_TIME',\n",
       " 'lexical_entity_count_CARDINAL',\n",
       " 'lexical_entity_frac_CARDINAL',\n",
       " 'lexical_entity_count_ORDINAL',\n",
       " 'lexical_entity_frac_ORDINAL',\n",
       " 'lexical_pos_count_PUNCT',\n",
       " 'lexical_pos_frac_PUNCT',\n",
       " 'lexical_pos_count_PROPN',\n",
       " 'lexical_pos_frac_PROPN',\n",
       " 'lexical_pos_count_NOUN',\n",
       " 'lexical_pos_frac_NOUN',\n",
       " 'lexical_pos_count_PRON',\n",
       " 'lexical_pos_frac_PRON',\n",
       " 'lexical_pos_count_VERB',\n",
       " 'lexical_pos_frac_VERB',\n",
       " 'lexical_pos_count_SCONJ',\n",
       " 'lexical_pos_frac_SCONJ',\n",
       " 'lexical_pos_count_NUM',\n",
       " 'lexical_pos_frac_NUM',\n",
       " 'lexical_pos_count_DET',\n",
       " 'lexical_pos_frac_DET',\n",
       " 'lexical_pos_count_CCONJ',\n",
       " 'lexical_pos_frac_CCONJ',\n",
       " 'lexical_pos_count_ADP',\n",
       " 'lexical_pos_frac_ADP',\n",
       " 'lexical_pos_count_AUX',\n",
       " 'lexical_pos_frac_AUX',\n",
       " 'lexical_pos_count_ADV',\n",
       " 'lexical_pos_frac_ADV',\n",
       " 'lexical_pos_count_ADJ',\n",
       " 'lexical_pos_frac_ADJ',\n",
       " 'lexical_pos_count_INTJ',\n",
       " 'lexical_pos_frac_INTJ',\n",
       " 'lexical_pos_count_X',\n",
       " 'lexical_pos_frac_X',\n",
       " 'lexical_pos_count_PART',\n",
       " 'lexical_pos_frac_PART',\n",
       " 'lexical_word_embedding_spacy_0',\n",
       " 'lexical_word_embedding_spacy_1',\n",
       " 'lexical_word_embedding_spacy_2',\n",
       " 'lexical_word_embedding_spacy_3',\n",
       " 'lexical_word_embedding_spacy_4',\n",
       " 'lexical_word_embedding_spacy_5',\n",
       " 'lexical_word_embedding_spacy_6',\n",
       " 'lexical_word_embedding_spacy_7',\n",
       " 'lexical_word_embedding_spacy_8',\n",
       " 'lexical_word_embedding_spacy_9',\n",
       " 'lexical_word_embedding_spacy_10',\n",
       " 'lexical_word_embedding_spacy_11',\n",
       " 'lexical_word_embedding_spacy_12',\n",
       " 'lexical_word_embedding_spacy_13',\n",
       " 'lexical_word_embedding_spacy_14',\n",
       " 'lexical_word_embedding_spacy_15',\n",
       " 'lexical_word_embedding_spacy_16',\n",
       " 'lexical_word_embedding_spacy_17',\n",
       " 'lexical_word_embedding_spacy_18',\n",
       " 'lexical_word_embedding_spacy_19',\n",
       " 'lexical_word_embedding_spacy_20',\n",
       " 'lexical_word_embedding_spacy_21',\n",
       " 'lexical_word_embedding_spacy_22',\n",
       " 'lexical_word_embedding_spacy_23',\n",
       " 'lexical_word_embedding_spacy_24',\n",
       " 'lexical_word_embedding_spacy_25',\n",
       " 'lexical_word_embedding_spacy_26',\n",
       " 'lexical_word_embedding_spacy_27',\n",
       " 'lexical_word_embedding_spacy_28',\n",
       " 'lexical_word_embedding_spacy_29',\n",
       " 'lexical_word_embedding_spacy_30',\n",
       " 'lexical_word_embedding_spacy_31',\n",
       " 'lexical_word_embedding_spacy_32',\n",
       " 'lexical_word_embedding_spacy_33',\n",
       " 'lexical_word_embedding_spacy_34',\n",
       " 'lexical_word_embedding_spacy_35',\n",
       " 'lexical_word_embedding_spacy_36',\n",
       " 'lexical_word_embedding_spacy_37',\n",
       " 'lexical_word_embedding_spacy_38',\n",
       " 'lexical_word_embedding_spacy_39',\n",
       " 'lexical_word_embedding_spacy_40',\n",
       " 'lexical_word_embedding_spacy_41',\n",
       " 'lexical_word_embedding_spacy_42',\n",
       " 'lexical_word_embedding_spacy_43',\n",
       " 'lexical_word_embedding_spacy_44',\n",
       " 'lexical_word_embedding_spacy_45',\n",
       " 'lexical_word_embedding_spacy_46',\n",
       " 'lexical_word_embedding_spacy_47',\n",
       " 'lexical_word_embedding_spacy_48',\n",
       " 'lexical_word_embedding_spacy_49',\n",
       " 'lexical_word_embedding_spacy_50',\n",
       " 'lexical_word_embedding_spacy_51',\n",
       " 'lexical_word_embedding_spacy_52',\n",
       " 'lexical_word_embedding_spacy_53',\n",
       " 'lexical_word_embedding_spacy_54',\n",
       " 'lexical_word_embedding_spacy_55',\n",
       " 'lexical_word_embedding_spacy_56',\n",
       " 'lexical_word_embedding_spacy_57',\n",
       " 'lexical_word_embedding_spacy_58',\n",
       " 'lexical_word_embedding_spacy_59',\n",
       " 'lexical_word_embedding_spacy_60',\n",
       " 'lexical_word_embedding_spacy_61',\n",
       " 'lexical_word_embedding_spacy_62',\n",
       " 'lexical_word_embedding_spacy_63',\n",
       " 'lexical_word_embedding_spacy_64',\n",
       " 'lexical_word_embedding_spacy_65',\n",
       " 'lexical_word_embedding_spacy_66',\n",
       " 'lexical_word_embedding_spacy_67',\n",
       " 'lexical_word_embedding_spacy_68',\n",
       " 'lexical_word_embedding_spacy_69',\n",
       " 'lexical_word_embedding_spacy_70',\n",
       " 'lexical_word_embedding_spacy_71',\n",
       " 'lexical_word_embedding_spacy_72',\n",
       " 'lexical_word_embedding_spacy_73',\n",
       " 'lexical_word_embedding_spacy_74',\n",
       " 'lexical_word_embedding_spacy_75',\n",
       " 'lexical_word_embedding_spacy_76',\n",
       " 'lexical_word_embedding_spacy_77',\n",
       " 'lexical_word_embedding_spacy_78',\n",
       " 'lexical_word_embedding_spacy_79',\n",
       " 'lexical_word_embedding_spacy_80',\n",
       " 'lexical_word_embedding_spacy_81',\n",
       " 'lexical_word_embedding_spacy_82',\n",
       " 'lexical_word_embedding_spacy_83',\n",
       " 'lexical_word_embedding_spacy_84',\n",
       " 'lexical_word_embedding_spacy_85',\n",
       " 'lexical_word_embedding_spacy_86',\n",
       " 'lexical_word_embedding_spacy_87',\n",
       " 'lexical_word_embedding_spacy_88',\n",
       " 'lexical_word_embedding_spacy_89',\n",
       " 'lexical_word_embedding_spacy_90',\n",
       " 'lexical_word_embedding_spacy_91',\n",
       " 'lexical_word_embedding_spacy_92',\n",
       " 'lexical_word_embedding_spacy_93',\n",
       " 'lexical_word_embedding_spacy_94',\n",
       " 'lexical_word_embedding_spacy_95',\n",
       " 'lexical_word_embedding_spacy_lemma_0',\n",
       " 'lexical_word_embedding_spacy_lemma_1',\n",
       " 'lexical_word_embedding_spacy_lemma_2',\n",
       " 'lexical_word_embedding_spacy_lemma_3',\n",
       " 'lexical_word_embedding_spacy_lemma_4',\n",
       " 'lexical_word_embedding_spacy_lemma_5',\n",
       " 'lexical_word_embedding_spacy_lemma_6',\n",
       " 'lexical_word_embedding_spacy_lemma_7',\n",
       " 'lexical_word_embedding_spacy_lemma_8',\n",
       " 'lexical_word_embedding_spacy_lemma_9',\n",
       " 'lexical_word_embedding_spacy_lemma_10',\n",
       " 'lexical_word_embedding_spacy_lemma_11',\n",
       " 'lexical_word_embedding_spacy_lemma_12',\n",
       " 'lexical_word_embedding_spacy_lemma_13',\n",
       " 'lexical_word_embedding_spacy_lemma_14',\n",
       " 'lexical_word_embedding_spacy_lemma_15',\n",
       " 'lexical_word_embedding_spacy_lemma_16',\n",
       " 'lexical_word_embedding_spacy_lemma_17',\n",
       " 'lexical_word_embedding_spacy_lemma_18',\n",
       " 'lexical_word_embedding_spacy_lemma_19',\n",
       " 'lexical_word_embedding_spacy_lemma_20',\n",
       " 'lexical_word_embedding_spacy_lemma_21',\n",
       " 'lexical_word_embedding_spacy_lemma_22',\n",
       " 'lexical_word_embedding_spacy_lemma_23',\n",
       " 'lexical_word_embedding_spacy_lemma_24',\n",
       " 'lexical_word_embedding_spacy_lemma_25',\n",
       " 'lexical_word_embedding_spacy_lemma_26',\n",
       " 'lexical_word_embedding_spacy_lemma_27',\n",
       " 'lexical_word_embedding_spacy_lemma_28',\n",
       " 'lexical_word_embedding_spacy_lemma_29',\n",
       " 'lexical_word_embedding_spacy_lemma_30',\n",
       " 'lexical_word_embedding_spacy_lemma_31',\n",
       " 'lexical_word_embedding_spacy_lemma_32',\n",
       " 'lexical_word_embedding_spacy_lemma_33',\n",
       " 'lexical_word_embedding_spacy_lemma_34',\n",
       " 'lexical_word_embedding_spacy_lemma_35',\n",
       " 'lexical_word_embedding_spacy_lemma_36',\n",
       " 'lexical_word_embedding_spacy_lemma_37',\n",
       " 'lexical_word_embedding_spacy_lemma_38',\n",
       " 'lexical_word_embedding_spacy_lemma_39',\n",
       " 'lexical_word_embedding_spacy_lemma_40',\n",
       " 'lexical_word_embedding_spacy_lemma_41',\n",
       " 'lexical_word_embedding_spacy_lemma_42',\n",
       " 'lexical_word_embedding_spacy_lemma_43',\n",
       " 'lexical_word_embedding_spacy_lemma_44',\n",
       " 'lexical_word_embedding_spacy_lemma_45',\n",
       " 'lexical_word_embedding_spacy_lemma_46',\n",
       " 'lexical_word_embedding_spacy_lemma_47',\n",
       " 'lexical_word_embedding_spacy_lemma_48',\n",
       " 'lexical_word_embedding_spacy_lemma_49',\n",
       " 'lexical_word_embedding_spacy_lemma_50',\n",
       " 'lexical_word_embedding_spacy_lemma_51',\n",
       " 'lexical_word_embedding_spacy_lemma_52',\n",
       " 'lexical_word_embedding_spacy_lemma_53',\n",
       " 'lexical_word_embedding_spacy_lemma_54',\n",
       " 'lexical_word_embedding_spacy_lemma_55',\n",
       " 'lexical_word_embedding_spacy_lemma_56',\n",
       " 'lexical_word_embedding_spacy_lemma_57',\n",
       " 'lexical_word_embedding_spacy_lemma_58',\n",
       " 'lexical_word_embedding_spacy_lemma_59',\n",
       " 'lexical_word_embedding_spacy_lemma_60',\n",
       " 'lexical_word_embedding_spacy_lemma_61',\n",
       " 'lexical_word_embedding_spacy_lemma_62',\n",
       " 'lexical_word_embedding_spacy_lemma_63',\n",
       " 'lexical_word_embedding_spacy_lemma_64',\n",
       " 'lexical_word_embedding_spacy_lemma_65',\n",
       " 'lexical_word_embedding_spacy_lemma_66',\n",
       " 'lexical_word_embedding_spacy_lemma_67',\n",
       " 'lexical_word_embedding_spacy_lemma_68',\n",
       " 'lexical_word_embedding_spacy_lemma_69',\n",
       " 'lexical_word_embedding_spacy_lemma_70',\n",
       " 'lexical_word_embedding_spacy_lemma_71',\n",
       " 'lexical_word_embedding_spacy_lemma_72',\n",
       " 'lexical_word_embedding_spacy_lemma_73',\n",
       " 'lexical_word_embedding_spacy_lemma_74',\n",
       " 'lexical_word_embedding_spacy_lemma_75',\n",
       " 'lexical_word_embedding_spacy_lemma_76',\n",
       " 'lexical_word_embedding_spacy_lemma_77',\n",
       " 'lexical_word_embedding_spacy_lemma_78',\n",
       " 'lexical_word_embedding_spacy_lemma_79',\n",
       " 'lexical_word_embedding_spacy_lemma_80',\n",
       " 'lexical_word_embedding_spacy_lemma_81',\n",
       " 'lexical_word_embedding_spacy_lemma_82',\n",
       " 'lexical_word_embedding_spacy_lemma_83',\n",
       " 'lexical_word_embedding_spacy_lemma_84',\n",
       " 'lexical_word_embedding_spacy_lemma_85',\n",
       " 'lexical_word_embedding_spacy_lemma_86',\n",
       " 'lexical_word_embedding_spacy_lemma_87',\n",
       " 'lexical_word_embedding_spacy_lemma_88',\n",
       " 'lexical_word_embedding_spacy_lemma_89',\n",
       " 'lexical_word_embedding_spacy_lemma_90',\n",
       " 'lexical_word_embedding_spacy_lemma_91',\n",
       " 'lexical_word_embedding_spacy_lemma_92',\n",
       " 'lexical_word_embedding_spacy_lemma_93',\n",
       " 'lexical_word_embedding_spacy_lemma_94',\n",
       " 'lexical_word_embedding_spacy_lemma_95']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_arr_np[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORDING_SESSION_LABEL</th>\n",
       "      <th>TRIAL_INDEX</th>\n",
       "      <th>CURRENT_FIX_X</th>\n",
       "      <th>CURRENT_FIX_Y</th>\n",
       "      <th>CURRENT_FIX_PUPIL</th>\n",
       "      <th>CURRENT_FIX_DURATION</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_ID</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_LABEL</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_PIXEL_AREA</th>\n",
       "      <th>CURRENT_FIX_INTEREST_AREA_RUN_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Trial_Recycled_</th>\n",
       "      <th>total_page</th>\n",
       "      <th>type</th>\n",
       "      <th>book_name</th>\n",
       "      <th>book</th>\n",
       "      <th>page</th>\n",
       "      <th>RT</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>page_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>msd001</td>\n",
       "      <td>4</td>\n",
       "      <td>71.8</td>\n",
       "      <td>118.2</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>177</td>\n",
       "      <td>4.0</td>\n",
       "      <td>of</td>\n",
       "      <td>4070.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19794.729413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>msd001</td>\n",
       "      <td>4</td>\n",
       "      <td>139.9</td>\n",
       "      <td>113.3</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>240</td>\n",
       "      <td>5.0</td>\n",
       "      <td>cigarette</td>\n",
       "      <td>7326.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19794.729413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>msd001</td>\n",
       "      <td>4</td>\n",
       "      <td>100.8</td>\n",
       "      <td>101.8</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>212</td>\n",
       "      <td>5.0</td>\n",
       "      <td>cigarette</td>\n",
       "      <td>7326.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19794.729413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>msd001</td>\n",
       "      <td>4</td>\n",
       "      <td>228.5</td>\n",
       "      <td>112.7</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>203</td>\n",
       "      <td>6.0</td>\n",
       "      <td>papers.</td>\n",
       "      <td>6290.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19794.729413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>msd001</td>\n",
       "      <td>4</td>\n",
       "      <td>232.4</td>\n",
       "      <td>131.8</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>312</td>\n",
       "      <td>6.0</td>\n",
       "      <td>papers.</td>\n",
       "      <td>6290.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>reading</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19794.729413</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "      <td>reading-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>msd001</td>\n",
       "      <td>9</td>\n",
       "      <td>519.9</td>\n",
       "      <td>271.3</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>question</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18566.772413</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>question-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>msd001</td>\n",
       "      <td>9</td>\n",
       "      <td>472.7</td>\n",
       "      <td>272.9</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>question</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18566.772413</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>question-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>msd001</td>\n",
       "      <td>9</td>\n",
       "      <td>543.6</td>\n",
       "      <td>264.4</td>\n",
       "      <td>2087.0</td>\n",
       "      <td>346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>question</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18566.772413</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>question-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>msd001</td>\n",
       "      <td>9</td>\n",
       "      <td>466.3</td>\n",
       "      <td>469.2</td>\n",
       "      <td>2075.0</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>question</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18566.772413</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>question-dickens-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>msd001</td>\n",
       "      <td>9</td>\n",
       "      <td>539.2</td>\n",
       "      <td>449.7</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>question</td>\n",
       "      <td>dickens</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18566.772413</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>question-dickens-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RECORDING_SESSION_LABEL  TRIAL_INDEX  CURRENT_FIX_X  CURRENT_FIX_Y  \\\n",
       "328                  msd001            4           71.8          118.2   \n",
       "329                  msd001            4          139.9          113.3   \n",
       "330                  msd001            4          100.8          101.8   \n",
       "331                  msd001            4          228.5          112.7   \n",
       "332                  msd001            4          232.4          131.8   \n",
       "..                      ...          ...            ...            ...   \n",
       "854                  msd001            9          519.9          271.3   \n",
       "855                  msd001            9          472.7          272.9   \n",
       "856                  msd001            9          543.6          264.4   \n",
       "857                  msd001            9          466.3          469.2   \n",
       "858                  msd001            9          539.2          449.7   \n",
       "\n",
       "     CURRENT_FIX_PUPIL  CURRENT_FIX_DURATION  CURRENT_FIX_INTEREST_AREA_ID  \\\n",
       "328             1822.0                   177                           4.0   \n",
       "329             1756.0                   240                           5.0   \n",
       "330             1700.0                   212                           5.0   \n",
       "331             1690.0                   203                           6.0   \n",
       "332             1749.0                   312                           6.0   \n",
       "..                 ...                   ...                           ...   \n",
       "854             2107.0                   149                           NaN   \n",
       "855             2105.0                   211                           NaN   \n",
       "856             2087.0                   346                           NaN   \n",
       "857             2075.0                   137                           NaN   \n",
       "858             2050.0                   129                           NaN   \n",
       "\n",
       "    CURRENT_FIX_INTEREST_AREA_LABEL  CURRENT_FIX_INTEREST_AREA_PIXEL_AREA  \\\n",
       "328                              of                                4070.0   \n",
       "329                       cigarette                                7326.0   \n",
       "330                       cigarette                                7326.0   \n",
       "331                         papers.                                6290.0   \n",
       "332                         papers.                                6290.0   \n",
       "..                              ...                                   ...   \n",
       "854                             NaN                                   NaN   \n",
       "855                             NaN                                   NaN   \n",
       "856                             NaN                                   NaN   \n",
       "857                             NaN                                   NaN   \n",
       "858                             NaN                                   NaN   \n",
       "\n",
       "     CURRENT_FIX_INTEREST_AREA_RUN_ID  ...  Trial_Recycled_ total_page  \\\n",
       "328                               1.0  ...             True          5   \n",
       "329                               1.0  ...             True          5   \n",
       "330                               1.0  ...             True          5   \n",
       "331                               1.0  ...             True          5   \n",
       "332                               1.0  ...             True          5   \n",
       "..                                ...  ...              ...        ...   \n",
       "854                               NaN  ...            False         13   \n",
       "855                               NaN  ...            False         13   \n",
       "856                               NaN  ...            False         13   \n",
       "857                               NaN  ...            False         13   \n",
       "858                               NaN  ...            False         13   \n",
       "\n",
       "         type  book_name  book page            RT answer  correct_answer  \\\n",
       "328   reading    dickens     1    4  19794.729413      1             -99   \n",
       "329   reading    dickens     1    4  19794.729413      1             -99   \n",
       "330   reading    dickens     1    4  19794.729413      1             -99   \n",
       "331   reading    dickens     1    4  19794.729413      1             -99   \n",
       "332   reading    dickens     1    4  19794.729413      1             -99   \n",
       "..        ...        ...   ...  ...           ...    ...             ...   \n",
       "854  question    dickens     1    4  18566.772413      4               4   \n",
       "855  question    dickens     1    4  18566.772413      4               4   \n",
       "856  question    dickens     1    4  18566.772413      4               4   \n",
       "857  question    dickens     1    4  18566.772413      4               4   \n",
       "858  question    dickens     1    4  18566.772413      4               4   \n",
       "\n",
       "              page_name  \n",
       "328   reading-dickens-4  \n",
       "329   reading-dickens-4  \n",
       "330   reading-dickens-4  \n",
       "331   reading-dickens-4  \n",
       "332   reading-dickens-4  \n",
       "..                  ...  \n",
       "854  question-dickens-4  \n",
       "855  question-dickens-4  \n",
       "856  question-dickens-4  \n",
       "857  question-dickens-4  \n",
       "858  question-dickens-4  \n",
       "\n",
       "[180 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr_np[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.6944444444444444 vs. 0.6944444444444444\n",
      "baseline: 0.6666666666666666 vs. 0.6666666666666666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4be90e777392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# rf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     pred_proba, best_parameters, rf = evaluate_rf.evaluate_rf(X_train, X_val, X_test,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                                           np.array(y_val[:, 2], dtype=int))\n",
      "\u001b[0;32m~/work/Projekte/AEye/reading-comprehension/rf_baseline/evaluate_rf.py\u001b[0m in \u001b[0;36mevaluate_rf\u001b[0;34m(X_train, X_val, X_test, y_train, y_val, param_grid)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# rf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_verbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             trees = [\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             trees = [\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             ]\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/Anaconda3/2020.11/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import evaluate_rf as evaluate_rf\n",
    "\n",
    "\n",
    "folds = 5\n",
    "rf_accs = []\n",
    "baseline_accs = []\n",
    "grid_search_verbosity = 1\n",
    "\n",
    "\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "best_param_list = []\n",
    "for f in range(folds):\n",
    "    # TODO: redo as stratifiedkfold over subjects\n",
    "    subjkeys = list(set(label_arr[:, 0]))\n",
    "    # set seeds (maybe define it as utils)\n",
    "    random.seed(f)\n",
    "    np.random.seed(f)\n",
    "    subjkeys = np.random.permutation(subjkeys) #random shuffling\n",
    "    \n",
    "    N_totalsub = len(subjkeys)\n",
    "    N_trainsub = round(0.8*N_totalsub)\n",
    "    N_validsub = round(0.1*N_totalsub)\n",
    "    N_testsub = N_totalsub - N_trainsub - N_validsub\n",
    "\n",
    "\n",
    "    N_train_sub = subjkeys[:N_trainsub]\n",
    "    N_val_sub = subjkeys[N_trainsub:N_trainsub + N_validsub]\n",
    "    N_test_sub = subjkeys[N_trainsub + N_validsub: N_trainsub + N_validsub + N_testsub]\n",
    "    X_train = data_arr_rf[np.isin(label_arr[:, 0], N_train_sub)]\n",
    "    X_val = data_arr_rf[np.isin(label_arr[:, 0], N_val_sub)]\n",
    "    X_test = data_arr_rf[np.isin(label_arr[:, 0], N_test_sub)]\n",
    "    y_train = label_arr[np.isin(label_arr[:, 0], N_train_sub)]\n",
    "    y_val = label_arr[np.isin(label_arr[:, 0], N_val_sub)]\n",
    "    y_test = label_arr[np.isin(label_arr[:, 0], N_test_sub)]\n",
    "        \n",
    "    # baseline \n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(X_train,np.array(y_train[:, 2], dtype=int))\n",
    "    \n",
    "    # rf\n",
    "    pred_proba, best_parameters, rf = evaluate_rf.evaluate_rf(X_train, X_val, X_test,\n",
    "                                                          np.array(y_train[:, 2], dtype=int), \n",
    "                                                          np.array(y_val[:, 2], dtype=int))\n",
    "    fpr, tpr, _ = metrics.roc_curve(np.array(y_test[:, 2], dtype=int), pred_proba[:,1], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    #print('auc: ' + str(auc))\n",
    "    aucs.append(auc)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    \n",
    "    baseline_accs.append(dummy_clf.score(X_test, np.array(y_test[:, 2], dtype=int)))\n",
    "    rf_accs.append(rf.score(X_test, np.array(y_test[:, 2], dtype=int)))\n",
    "    print('baseline: ' + str(baseline_accs[-1]) + ' vs. ' + str(rf_accs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'baseline: {np.mean(baseline_accs)} +/- {np.std(baseline_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'rf: {np.mean(rf_accs)} +/- {np.std(rf_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_utils.avg_fnr_fpr_curve(fprs, tprs, label = 'RF', plot_random=True,\n",
    "                    title = None, plot_statistics = False,\n",
    "                    loc = 'best', plot_legend = True,\n",
    "                    plot_points = 10000, ncol=1,\n",
    "                    bbox_to_anchor=None,\n",
    "                    starting_point = None,\n",
    "                    fontsize = 14, xscale = None)\n",
    "plt.title('AUC: ' + str(np.mean(aucs)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN', 'NOUN', 'PROPN', 'NOUN', 'NOUN', 'PROPN']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_list = [[100],[],[300,100],[],[200],[300,100],[50]]\n",
    "fixations_numbers = [[0],[],[1,2],[],[3],[4,5],[6]]\n",
    "regression_values = [[0],[],[-10,1],[],[1],[3,7],[4]]\n",
    "word_list = ['ich','Wednesday','Paul','ich','heiße','Paul','nan']\n",
    "sentence_id_list = [0,0,0,1,1,1,1]\n",
    "suprisal_list = [0,0,0,1,1,1,1]\n",
    "pos_tagger = 'spacy'\n",
    "word_cluster_thresholds = [(1,1),(2,2),(3,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, feature_names = rf_feature_extraction.get_linguistic_features_for_lists(\n",
    "                        fixation_list = [[100],[],[300,100],[],[200],[300,100]],\n",
    "                        fixations_numbers = [[0],[],[1,2],[],[3],[4,5]],\n",
    "                        regression_values = [[0],[],[-10,1],[],[1],[3,7]],\n",
    "                        word_list = ['I','am','David','and','I','like'],\n",
    "                        sentence_id_list = [0,0,0,1,1,1],\n",
    "                        suprisal_list = [0,0,0,1,1,1,1],\n",
    "                        pos_tagger = 'spacy',\n",
    "                        word_cluster_thresholds = [(1,1),(2,2),(3,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 6)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 2., 0., 0., 0.]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[np.where(np.array(feature_names) == 'dependencies_right')[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[np.where(np.array(feature_names) == 'dependencies_left')[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ff',\n",
       " 'tf',\n",
       " 'wfc_ff_nomarlized',\n",
       " 'wfc_ff_normalized',\n",
       " 'sc_ff_normalized',\n",
       " 'sc_tf_normalized',\n",
       " 'ic_ff_normalized',\n",
       " 'regression',\n",
       " 'num_regressions',\n",
       " 'num_progressions',\n",
       " 'surprisal',\n",
       " 'word_len',\n",
       " 'dependencies_right',\n",
       " 'dependencies_left',\n",
       " 'is_entity_',\n",
       " 'is_entity_DATE',\n",
       " 'is_entity_QUANTITY',\n",
       " 'is_entity_ORG',\n",
       " 'is_entity_GPE',\n",
       " 'is_entity_NORP',\n",
       " 'is_entity_PERSON',\n",
       " 'is_entity_TIME',\n",
       " 'is_entity_CARDINAL',\n",
       " 'is_entity_ORDINAL',\n",
       " 'is_entity_NaN',\n",
       " 'is_pos_PUNCT',\n",
       " 'is_pos_PROPN',\n",
       " 'is_pos_NOUN',\n",
       " 'is_pos_PRON',\n",
       " 'is_pos_VERB',\n",
       " 'is_pos_SCONJ',\n",
       " 'is_pos_NUM',\n",
       " 'is_pos_DET',\n",
       " 'is_pos_CCONJ',\n",
       " 'is_pos_ADP',\n",
       " 'is_pos_AUX',\n",
       " 'is_pos_ADV',\n",
       " 'is_pos_ADJ',\n",
       " 'is_pos_INTJ',\n",
       " 'is_pos_X',\n",
       " 'is_pos_PART',\n",
       " 'is_content_word_CONTENT',\n",
       " 'is_content_word_NO_CONTENT',\n",
       " 'is_content_word_UNKNOWN',\n",
       " 'is_reduced_pos_ADJ',\n",
       " 'is_reduced_pos_FUNC',\n",
       " 'is_reduced_pos_NOUN',\n",
       " 'is_reduced_pos_UNKNOWN',\n",
       " 'is_reduced_pos_VERB']"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "\n",
    "def parse_dependency(text) -> Tuple[List[Any], ...]:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab, token_match=re.compile(r'\\S+').match)\n",
    "    doc = nlp(text)\n",
    "    n_rights =  [[] for _ in range(len(text.split()))]\n",
    "    n_lefts = [[] for _ in range(len(text.split()))]\n",
    "    rights = [[] for _ in range(len(text.split()))]\n",
    "    lefts = [[] for _ in range(len(text.split()))]\n",
    "    deps = [[] for _ in range(len(text.split()))]\n",
    "\n",
    "    for idx, token in enumerate(doc):\n",
    "        deps[idx] = token.dep_\n",
    "        rights[idx] = list(token.rights)\n",
    "        lefts[idx] = list(token.lefts)\n",
    "        n_rights[idx] = token.n_rights\n",
    "        n_lefts[idx] = token.n_lefts\n",
    "    return deps, n_rights, rights, n_lefts, lefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['nsubj', 'ROOT', 'attr', 'cc', 'conj', 'conj'], [0, 2, 2, 0, 0, 0], [[], [David, like], [and, I], [], [], []], [0, 1, 0, 0, 0, 0], [[], [I], [], [], [], []])\n"
     ]
    }
   ],
   "source": [
    "word_list = ['I','am','David','and','I','like']\n",
    "print(parse_dependency(' '.join(word_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(features[np.where(np.array(feature_names) == 'is_content_word_UNKNOWN')[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(features[np.where(np.array(feature_names) == 'is_entity_DATE')[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(features[np.where(np.array(feature_names) == 'is_entity_')[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(features[np.where(np.array(feature_names) == 'is_entity_ORG')[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(features[np.where(np.array(feature_names) == 'is_entity_NaN')[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 6)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ff',\n",
       " 'tf',\n",
       " 'wfc_ff_nomarlized',\n",
       " 'wfc_ff_normalized',\n",
       " 'sc_ff_normalized',\n",
       " 'sc_tf_normalized',\n",
       " 'ic_ff_normalized',\n",
       " 'regression',\n",
       " 'num_regressions',\n",
       " 'num_progressions',\n",
       " 'surprisal',\n",
       " 'word_len',\n",
       " 'is_entity_',\n",
       " 'is_entity_DATE',\n",
       " 'is_entity_QUANTITY',\n",
       " 'is_entity_ORG',\n",
       " 'is_entity_GPE',\n",
       " 'is_entity_NORP',\n",
       " 'is_entity_PERSON',\n",
       " 'is_entity_TIME',\n",
       " 'is_entity_CARDINAL',\n",
       " 'is_entity_ORDINAL',\n",
       " 'is_entity_NaN',\n",
       " 'is_pos_PUNCT',\n",
       " 'is_pos_PROPN',\n",
       " 'is_pos_NOUN',\n",
       " 'is_pos_PRON',\n",
       " 'is_pos_VERB',\n",
       " 'is_pos_SCONJ',\n",
       " 'is_pos_NUM',\n",
       " 'is_pos_DET',\n",
       " 'is_pos_CCONJ',\n",
       " 'is_pos_ADP',\n",
       " 'is_pos_AUX',\n",
       " 'is_pos_ADV',\n",
       " 'is_pos_ADJ',\n",
       " 'is_pos_INTJ',\n",
       " 'is_pos_X',\n",
       " 'is_pos_PART']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN', 'NOUN', 'PROPN', 'NOUN', 'NOUN', 'PROPN', 'NaN']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feature_extraction.get_list_of_pos_tags(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ff',\n",
       " 'tf',\n",
       " 'wfc_ff_nomarlized',\n",
       " 'wfc_ff_normalized',\n",
       " 'sc_ff_normalized',\n",
       " 'sc_tf_normalized',\n",
       " 'ic_ff_normalized',\n",
       " 'regression',\n",
       " 'num_regressions',\n",
       " 'num_progressions',\n",
       " 'surprisal']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.        ,   0.        , 300.        ,   0.        ,\n",
       "        200.        , 300.        ],\n",
       "       [100.        ,   0.        , 400.        ,   0.        ,\n",
       "        200.        , 400.        ],\n",
       "       [  0.5       ,   0.        ,   1.5       ,   0.        ,\n",
       "          0.8       ,   1.2       ],\n",
       "       [  0.4       ,   0.        ,   1.6       ,   0.        ,\n",
       "          0.66666667,   1.33333333],\n",
       "       [  0.66666667,   0.        ,   1.        ,   0.        ,\n",
       "          1.33333333,   1.        ],\n",
       "       [  0.66666667,   0.        ,   1.        ,   0.        ,\n",
       "          1.33333333,   1.        ],\n",
       "       [  1.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,  -4.5       ,   0.        ,\n",
       "          1.        ,   5.        ],\n",
       "       [  0.        ,   0.        ,   1.        ,   0.        ,\n",
       "          1.        ,   2.        ],\n",
       "       [  0.        ,   0.        ,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          1.        ,   1.        ]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [100]}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cluster_threshold_ff_fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+02,  0.00000000e+00,  3.00000000e+02,\n",
       "         0.00000000e+00,  2.00000000e+02,  3.00000000e+02],\n",
       "       [ 1.00000000e+02,  0.00000000e+00,  4.00000000e+02,\n",
       "         0.00000000e+00,  2.00000000e+02,  4.00000000e+02],\n",
       "       [ 5.00000000e-01,  0.00000000e+00,  1.50000000e+00,\n",
       "         0.00000000e+00,  8.00000000e-01,  1.20000000e+00],\n",
       "       [ 4.00000000e-01,  0.00000000e+00,  1.60000000e+00,\n",
       "         0.00000000e+00,  6.66666667e-01,  1.33333333e+00],\n",
       "       [ 4.44444444e-01,  0.00000000e+00,  1.33333333e+00,\n",
       "         0.00000000e+00,  8.88888889e-01,  1.33333333e+00],\n",
       "       [ 3.63636364e-01,  0.00000000e+00,  1.45454545e+00,\n",
       "         0.00000000e+00,  7.27272727e-01,  1.45454545e+00],\n",
       "       [ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00, -4.50000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  5.00000000e+00]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [100, 100]}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cluster_threshold_tf_fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [100, 200, 400], 1: [100, 200, 400]}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_sentence_tf_fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [100, 200, 300], 1: [100, 200, 300]}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_sentence_ff_fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-5d8f1a647b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwfc_ff_nomarlized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwfc_ff_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msc_ff_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ff' is not defined"
     ]
    }
   ],
   "source": [
    "ff\n",
    "tf\n",
    "wfc_ff_nomarlized\n",
    "wfc_tf_normalized\n",
    "sc_ff_normalized\n",
    "sc_tf_normalized\n",
    "ic_ff_normalized\n",
    "regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642490055.7225032\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18\n"
     ]
    }
   ],
   "source": [
    "today = datetime.date.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "year,month,day = str(today).split('-')\n",
    "year = int(year)\n",
    "month = int(month)\n",
    "day = int(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18 08:26:17.598003\n"
     ]
    }
   ],
   "source": [
    "today = datetime.datetime.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime(2022,1,18,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86286\n",
      "14286\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime(2022,1,18,9)\n",
    "end_time = datetime.datetime(2022,1,18,13)\n",
    "today = datetime.datetime.today()\n",
    "delta_start = start_time - today\n",
    "delta_end = end_time - today\n",
    "if delta_start.seconds < 0 and delta_end.seconds > 0:\n",
    "    print('run')    \n",
    "elif delta_start.seconds < 0 and delta_end.seconds < 0:\n",
    "    sys.exit()\n",
    "print(delta_start.seconds)\n",
    "print(delta_end.seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time < today and end_time > today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time < today and  end_time < today"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
