{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:07.594827Z",
     "start_time": "2023-08-30T06:45:17.616473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting numerical features:   0%|          | 0/900 [00:00<?, ?it/s]/Users/debor/repos/PoTeC/extract_features_rf.py:935: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  return skew(not_nan_values)\n",
      "/Users/debor/repos/PoTeC/extract_features_rf.py:938: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  return kurtosis(not_nan_values)\n",
      "Extracting numerical features: 100%|██████████| 900/900 [00:20<00:00, 43.52it/s]\n",
      "Extracting lexical features: 100%|██████████| 900/900 [2:04:19<00:00,  8.29s/it]    \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from extract_features_rf import get_combined_features\n",
    "\n",
    "\n",
    "DATA_FOLDER_PATH = '/Users/debor/repos/PoTeC-data/eyetracking_data/scanpaths_reader_rm_wf'\n",
    "\n",
    "paths = list(Path(DATA_FOLDER_PATH).glob('*.txt'))\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, sep='\\t', na_values=['None', '.'])\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "data_arr, feature_names = get_combined_features(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:07.613271Z",
     "start_time": "2023-08-30T08:50:07.598083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     CURRENT_FIX_DURATION_mean  CURRENT_FIX_DURATION_std   \n0                   196.361343                 92.259651  \\\n1                   196.340973                 67.509064   \n2                   209.595139                 80.511436   \n3                   171.326538                 87.716637   \n4                   213.942856                 65.469948   \n..                         ...                       ...   \n895                 220.777771                 81.548592   \n896                 239.742432                121.603416   \n897                 198.405029                124.120804   \n898                 196.111115                 70.513847   \n899                 220.940292                 72.081940   \n\n     CURRENT_FIX_DURATION_median  CURRENT_FIX_DURATION_skew   \n0                          187.0                   1.268841  \\\n1                          190.0                   2.542669   \n2                          194.5                   1.836004   \n3                          159.0                   2.967913   \n4                          214.0                   0.668290   \n..                           ...                        ...   \n895                        209.5                   2.567144   \n896                        210.5                   2.166776   \n897                        178.5                   5.289953   \n898                        184.0                   1.269712   \n899                        216.0                   2.124933   \n\n     CURRENT_FIX_DURATION_kurtosis    roi_mean     roi_std  roi_median   \n0                         5.181818  545.978149  313.589050       561.0  \\\n1                        15.811152  460.945557  281.162292       442.0   \n2                         8.130287  410.882599  264.934082       408.0   \n3                        14.168442  561.787170  278.160645       559.0   \n4                         2.336957  449.279358  264.568909       455.0   \n..                             ...         ...         ...         ...   \n895                      14.898708  535.138916  276.385071       556.5   \n896                       7.322240  491.271057  305.496948       482.0   \n897                      49.230427  461.932953  341.265015       348.0   \n898                       3.416124  489.241821  276.006836       468.0   \n899                      13.241494  487.880585  308.251007       439.0   \n\n     roi_skew  roi_kurtosis  ...  lexical_word_embedding_spacy_lemma_86   \n0   -0.015030     -1.201969  ...                               0.348818  \\\n1    0.454465     -0.653694  ...                               0.311055   \n2    0.177709     -1.173818  ...                               0.303842   \n3   -0.071132     -0.970753  ...                               0.111021   \n4    0.025539     -1.157084  ...                               0.291815   \n..        ...           ...  ...                                    ...   \n895 -0.265825     -1.135572  ...                               0.069051   \n896  0.059148     -1.184529  ...                               0.237014   \n897  0.451358     -1.100906  ...                               0.309779   \n898  0.171846     -0.985881  ...                               0.317854   \n899  0.247172     -1.175561  ...                               0.249141   \n\n     lexical_word_embedding_spacy_lemma_87   \n0                                -0.098345  \\\n1                                -0.096699   \n2                                -0.097198   \n3                                -0.017154   \n4                                -0.069483   \n..                                     ...   \n895                              -0.093141   \n896                              -0.054264   \n897                              -0.069427   \n898                              -0.122346   \n899                              -0.078023   \n\n     lexical_word_embedding_spacy_lemma_88   \n0                                -0.415426  \\\n1                                -0.408950   \n2                                -0.291308   \n3                                -0.451527   \n4                                -0.323504   \n..                                     ...   \n895                              -0.414736   \n896                              -0.336871   \n897                              -0.314597   \n898                              -0.464454   \n899                              -0.349136   \n\n     lexical_word_embedding_spacy_lemma_89   \n0                                -0.136097  \\\n1                                -0.165718   \n2                                -0.141470   \n3                                -0.222214   \n4                                -0.185709   \n..                                     ...   \n895                              -0.077777   \n896                              -0.231749   \n897                              -0.191150   \n898                              -0.088481   \n899                              -0.155012   \n\n     lexical_word_embedding_spacy_lemma_90   \n0                                -0.473930  \\\n1                                -0.402917   \n2                                -0.574067   \n3                                -0.303739   \n4                                -0.563363   \n..                                     ...   \n895                              -0.396381   \n896                              -0.613936   \n897                              -0.363702   \n898                              -0.569035   \n899                              -0.564468   \n\n     lexical_word_embedding_spacy_lemma_91   \n0                                -0.365978  \\\n1                                -0.339687   \n2                                -0.313650   \n3                                -0.304234   \n4                                -0.291159   \n..                                     ...   \n895                              -0.383954   \n896                              -0.339112   \n897                              -0.282544   \n898                              -0.303349   \n899                              -0.345912   \n\n     lexical_word_embedding_spacy_lemma_92   \n0                                -0.499586  \\\n1                                -0.465964   \n2                                -0.507244   \n3                                -0.564872   \n4                                -0.484449   \n..                                     ...   \n895                              -0.466554   \n896                              -0.522419   \n897                              -0.431772   \n898                              -0.467401   \n899                              -0.501453   \n\n     lexical_word_embedding_spacy_lemma_93   \n0                                 0.279461  \\\n1                                 0.272932   \n2                                 0.360266   \n3                                 0.246955   \n4                                 0.320729   \n..                                     ...   \n895                               0.294311   \n896                               0.259881   \n897                               0.223544   \n898                               0.238378   \n899                               0.223226   \n\n     lexical_word_embedding_spacy_lemma_94   \n0                                 0.871738  \\\n1                                 0.813951   \n2                                 0.838996   \n3                                 0.818862   \n4                                 0.841880   \n..                                     ...   \n895                               1.019377   \n896                               0.984458   \n897                               0.887344   \n898                               0.991982   \n899                               0.969624   \n\n     lexical_word_embedding_spacy_lemma_95  \n0                                 0.217742  \n1                                 0.174176  \n2                                 0.177530  \n3                                 0.318269  \n4                                 0.214453  \n..                                     ...  \n895                               0.194179  \n896                               0.147186  \n897                               0.330846  \n898                               0.158073  \n899                               0.157403  \n\n[900 rows x 391 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CURRENT_FIX_DURATION_mean</th>\n      <th>CURRENT_FIX_DURATION_std</th>\n      <th>CURRENT_FIX_DURATION_median</th>\n      <th>CURRENT_FIX_DURATION_skew</th>\n      <th>CURRENT_FIX_DURATION_kurtosis</th>\n      <th>roi_mean</th>\n      <th>roi_std</th>\n      <th>roi_median</th>\n      <th>roi_skew</th>\n      <th>roi_kurtosis</th>\n      <th>...</th>\n      <th>lexical_word_embedding_spacy_lemma_86</th>\n      <th>lexical_word_embedding_spacy_lemma_87</th>\n      <th>lexical_word_embedding_spacy_lemma_88</th>\n      <th>lexical_word_embedding_spacy_lemma_89</th>\n      <th>lexical_word_embedding_spacy_lemma_90</th>\n      <th>lexical_word_embedding_spacy_lemma_91</th>\n      <th>lexical_word_embedding_spacy_lemma_92</th>\n      <th>lexical_word_embedding_spacy_lemma_93</th>\n      <th>lexical_word_embedding_spacy_lemma_94</th>\n      <th>lexical_word_embedding_spacy_lemma_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196.361343</td>\n      <td>92.259651</td>\n      <td>187.0</td>\n      <td>1.268841</td>\n      <td>5.181818</td>\n      <td>545.978149</td>\n      <td>313.589050</td>\n      <td>561.0</td>\n      <td>-0.015030</td>\n      <td>-1.201969</td>\n      <td>...</td>\n      <td>0.348818</td>\n      <td>-0.098345</td>\n      <td>-0.415426</td>\n      <td>-0.136097</td>\n      <td>-0.473930</td>\n      <td>-0.365978</td>\n      <td>-0.499586</td>\n      <td>0.279461</td>\n      <td>0.871738</td>\n      <td>0.217742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>196.340973</td>\n      <td>67.509064</td>\n      <td>190.0</td>\n      <td>2.542669</td>\n      <td>15.811152</td>\n      <td>460.945557</td>\n      <td>281.162292</td>\n      <td>442.0</td>\n      <td>0.454465</td>\n      <td>-0.653694</td>\n      <td>...</td>\n      <td>0.311055</td>\n      <td>-0.096699</td>\n      <td>-0.408950</td>\n      <td>-0.165718</td>\n      <td>-0.402917</td>\n      <td>-0.339687</td>\n      <td>-0.465964</td>\n      <td>0.272932</td>\n      <td>0.813951</td>\n      <td>0.174176</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>209.595139</td>\n      <td>80.511436</td>\n      <td>194.5</td>\n      <td>1.836004</td>\n      <td>8.130287</td>\n      <td>410.882599</td>\n      <td>264.934082</td>\n      <td>408.0</td>\n      <td>0.177709</td>\n      <td>-1.173818</td>\n      <td>...</td>\n      <td>0.303842</td>\n      <td>-0.097198</td>\n      <td>-0.291308</td>\n      <td>-0.141470</td>\n      <td>-0.574067</td>\n      <td>-0.313650</td>\n      <td>-0.507244</td>\n      <td>0.360266</td>\n      <td>0.838996</td>\n      <td>0.177530</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>171.326538</td>\n      <td>87.716637</td>\n      <td>159.0</td>\n      <td>2.967913</td>\n      <td>14.168442</td>\n      <td>561.787170</td>\n      <td>278.160645</td>\n      <td>559.0</td>\n      <td>-0.071132</td>\n      <td>-0.970753</td>\n      <td>...</td>\n      <td>0.111021</td>\n      <td>-0.017154</td>\n      <td>-0.451527</td>\n      <td>-0.222214</td>\n      <td>-0.303739</td>\n      <td>-0.304234</td>\n      <td>-0.564872</td>\n      <td>0.246955</td>\n      <td>0.818862</td>\n      <td>0.318269</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>213.942856</td>\n      <td>65.469948</td>\n      <td>214.0</td>\n      <td>0.668290</td>\n      <td>2.336957</td>\n      <td>449.279358</td>\n      <td>264.568909</td>\n      <td>455.0</td>\n      <td>0.025539</td>\n      <td>-1.157084</td>\n      <td>...</td>\n      <td>0.291815</td>\n      <td>-0.069483</td>\n      <td>-0.323504</td>\n      <td>-0.185709</td>\n      <td>-0.563363</td>\n      <td>-0.291159</td>\n      <td>-0.484449</td>\n      <td>0.320729</td>\n      <td>0.841880</td>\n      <td>0.214453</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>220.777771</td>\n      <td>81.548592</td>\n      <td>209.5</td>\n      <td>2.567144</td>\n      <td>14.898708</td>\n      <td>535.138916</td>\n      <td>276.385071</td>\n      <td>556.5</td>\n      <td>-0.265825</td>\n      <td>-1.135572</td>\n      <td>...</td>\n      <td>0.069051</td>\n      <td>-0.093141</td>\n      <td>-0.414736</td>\n      <td>-0.077777</td>\n      <td>-0.396381</td>\n      <td>-0.383954</td>\n      <td>-0.466554</td>\n      <td>0.294311</td>\n      <td>1.019377</td>\n      <td>0.194179</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>239.742432</td>\n      <td>121.603416</td>\n      <td>210.5</td>\n      <td>2.166776</td>\n      <td>7.322240</td>\n      <td>491.271057</td>\n      <td>305.496948</td>\n      <td>482.0</td>\n      <td>0.059148</td>\n      <td>-1.184529</td>\n      <td>...</td>\n      <td>0.237014</td>\n      <td>-0.054264</td>\n      <td>-0.336871</td>\n      <td>-0.231749</td>\n      <td>-0.613936</td>\n      <td>-0.339112</td>\n      <td>-0.522419</td>\n      <td>0.259881</td>\n      <td>0.984458</td>\n      <td>0.147186</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>198.405029</td>\n      <td>124.120804</td>\n      <td>178.5</td>\n      <td>5.289953</td>\n      <td>49.230427</td>\n      <td>461.932953</td>\n      <td>341.265015</td>\n      <td>348.0</td>\n      <td>0.451358</td>\n      <td>-1.100906</td>\n      <td>...</td>\n      <td>0.309779</td>\n      <td>-0.069427</td>\n      <td>-0.314597</td>\n      <td>-0.191150</td>\n      <td>-0.363702</td>\n      <td>-0.282544</td>\n      <td>-0.431772</td>\n      <td>0.223544</td>\n      <td>0.887344</td>\n      <td>0.330846</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>196.111115</td>\n      <td>70.513847</td>\n      <td>184.0</td>\n      <td>1.269712</td>\n      <td>3.416124</td>\n      <td>489.241821</td>\n      <td>276.006836</td>\n      <td>468.0</td>\n      <td>0.171846</td>\n      <td>-0.985881</td>\n      <td>...</td>\n      <td>0.317854</td>\n      <td>-0.122346</td>\n      <td>-0.464454</td>\n      <td>-0.088481</td>\n      <td>-0.569035</td>\n      <td>-0.303349</td>\n      <td>-0.467401</td>\n      <td>0.238378</td>\n      <td>0.991982</td>\n      <td>0.158073</td>\n    </tr>\n    <tr>\n      <th>899</th>\n      <td>220.940292</td>\n      <td>72.081940</td>\n      <td>216.0</td>\n      <td>2.124933</td>\n      <td>13.241494</td>\n      <td>487.880585</td>\n      <td>308.251007</td>\n      <td>439.0</td>\n      <td>0.247172</td>\n      <td>-1.175561</td>\n      <td>...</td>\n      <td>0.249141</td>\n      <td>-0.078023</td>\n      <td>-0.349136</td>\n      <td>-0.155012</td>\n      <td>-0.564468</td>\n      <td>-0.345912</td>\n      <td>-0.501453</td>\n      <td>0.223226</td>\n      <td>0.969624</td>\n      <td>0.157403</td>\n    </tr>\n  </tbody>\n</table>\n<p>900 rows × 391 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_arr, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T07:44:06.181666Z",
     "start_time": "2023-08-31T07:44:06.167718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "391"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:07.701639Z",
     "start_time": "2023-08-30T08:50:07.672599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 900 900 900\n"
     ]
    }
   ],
   "source": [
    "# get the reader id, the group, item id and the expert level from all the dfs in the list\n",
    "reader_ids = [df['reader'].iloc[0] for df in dfs]\n",
    "groups = [df['group'].iloc[0] for df in dfs]\n",
    "expert_levels = [df['expert_status'].iloc[0] for df in dfs]\n",
    "item_ids = [df['itemid'].iloc[0] for df in dfs]\n",
    "print(len(reader_ids), len(groups), len(expert_levels), len(item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:07.705638Z",
     "start_time": "2023-08-30T08:50:07.702832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[95, 22, 1, 75, 73, 80, 7, 75, 1, 79]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_ids[890:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:08.002860Z",
     "start_time": "2023-08-30T08:50:07.706763Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 21\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:08.006339Z",
     "start_time": "2023-08-30T08:50:08.004004Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_arr\n",
    "y = np.array(expert_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:08.010361Z",
     "start_time": "2023-08-30T08:50:08.008289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num experts: 564\n",
      "Num beginners: 336\n",
      "Majority voting: 0.6266666666666667\n"
     ]
    }
   ],
   "source": [
    "if len(np.unique(y)) == 4:\n",
    "    print(f'Num bio-experts: {np.count_nonzero(y == 2)}')\n",
    "    print(f'Num bio-beginners: {np.count_nonzero(y == 1)}')\n",
    "    print(f'Num physik-experts: {np.count_nonzero(y == 4)}')\n",
    "    print(f'Num physik-beginners: {np.count_nonzero(y == 3)}')\n",
    "\n",
    "else:\n",
    "    experts = np.count_nonzero(y == 1)\n",
    "    beginners = np.count_nonzero(y == -1)\n",
    "    print(f'Num experts: {experts}')\n",
    "    print(f'Num beginners: {beginners}')\n",
    "    print(f'Accuracy majority voting: {(experts if experts > beginners else beginners) / (experts + beginners)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T08:50:08.013319Z",
     "start_time": "2023-08-30T08:50:08.011285Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 300, 400, 500, 700, 900, 1000, 1200],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth' : [2, 4, 8, 16, 32, 64, None],\n",
    "    'criterion' :['entropy', 'gini', 'log_loss'],\n",
    "    'random_state': [RANDOM_STATE],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "grid_search_verbosity = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class DebugFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.levelno == logging.DEBUG\n",
    "\n",
    "def get_logger():\n",
    "    \n",
    "        # configuration for log file\n",
    "    log = logging.getLogger('rf-baseline-grid-search')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    # configure separate logging handlers for info and debug to separate files\n",
    "    info_log = logging.FileHandler(f'hparams_search/grid_search_rf_baseline_info_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "    info_log.setLevel(logging.INFO)\n",
    "    info_log.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    debug_log = logging.FileHandler(f'hparams_search/grid_search_rf_baseline_debug_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "    debug_log.setLevel(logging.DEBUG)\n",
    "    debug_log.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))\n",
    "    # configure filter to ignore all messages higher than debug for the debug file\n",
    "    debug_log.addFilter(DebugFilter())\n",
    "    \n",
    "    logging.getLogger().addHandler(info_log)\n",
    "    logging.getLogger().addHandler(debug_log)\n",
    "        \n",
    "    # log info logger filename to debug handler\n",
    "    log.debug(f'Info logger filename: {info_log.baseFilename}')\n",
    "        \n",
    "    \n",
    "    return log"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T09:07:43.751991Z",
     "start_time": "2023-08-30T09:07:43.741103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T07:31:27.184266Z",
     "start_time": "2023-08-30T13:23:48.738604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 567 candidates, totalling 2835 fits\n",
      "Fitting 5 folds for each of 567 candidates, totalling 2835 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 567 candidates, totalling 2835 fits\n",
      "Fitting 5 folds for each of 567 candidates, totalling 2835 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 567 candidates, totalling 2835 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debor/opt/anaconda3/envs/PoTeC/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean score: 50.94\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "kf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "split_criterion = reader_ids\n",
    "split_criterion_str = 'reader'\n",
    "scores = []\n",
    "outer_fold = 1\n",
    "best_score = 0\n",
    "best_hparams = None\n",
    "\n",
    "logger.info(f'Grid search for random forest baseline. New {split_criterion_str} split.\\nStarted at {datetime.now()}')\n",
    "logger.info(f'Grid search parameters: {param_grid}')\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X, y, groups=split_criterion):\n",
    "    logger.info(f'Outer fold {outer_fold}')\n",
    "    logger.debug(f'Outer fold {outer_fold}')\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    outer_train_ids = [split_criterion[i] for i in train_index]\n",
    "    outer_test_ids = [split_criterion[i] for i in test_index]\n",
    "    \n",
    "    logger.info(f'Outer train {split_criterion_str}-ids: {sorted(set(outer_train_ids))}')\n",
    "    logger.info(f'Outer test {split_criterion_str}-ids: {sorted(set(outer_test_ids))}')\n",
    "    logger.debug(f'Outer train data indices: {train_index}')\n",
    "    logger.debug(f'Outer test data indices: {test_index}')\n",
    "    logger.debug(f'Outer train data labels: {y_train}')\n",
    "    logger.debug(f'Outer test data labels: {y_test}')    \n",
    "    logger.debug(f'Inner train {split_criterion_str}-ids: {outer_train_ids}')\n",
    "    logger.debug(f'Inner test {split_criterion_str}-ids: {outer_train_ids}')\n",
    "    \n",
    "    inner_kf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "    # standardize/normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    # fit data on training set\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    # standardize test data as well\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    \n",
    "    cv_list = list(inner_kf.split(X_train_std, y_train, groups=outer_train_ids))\n",
    "    \n",
    "    for inner_fold_idx, (train, test) in enumerate(cv_list):\n",
    "        inner_train_ids = [outer_train_ids[i] for i in train]\n",
    "        inner_test_ids = [outer_train_ids[i] for i in test]\n",
    "        \n",
    "        logger.info(f'Inner fold {inner_fold_idx + 1}')\n",
    "        logger.debug(f'Inner fold {inner_fold_idx + 1}')\n",
    "        \n",
    "        logger.info(f'Inner train {split_criterion_str}-ids: {sorted(set(inner_train_ids))}')\n",
    "        logger.info(f'Inner test {split_criterion_str}-ids: {sorted(set(inner_test_ids))}')\n",
    "        \n",
    "        logger.debug(f'Inner train data indices on outer train data: {train}')\n",
    "        logger.debug(f'Inner test data indices on outer train data: {test}')\n",
    "        logger.debug(f'Inner train data labels on outer train data: {y_train[train]}')\n",
    "        logger.debug(f'Inner test data labels on outer train data: {y_train[test]}')\n",
    "        logger.debug(f'Inner train {split_criterion_str}-ids: {inner_train_ids}')\n",
    "        logger.debug(f'Inner test {split_criterion_str}-ids: {inner_test_ids}')\n",
    "        \n",
    "\n",
    "    rf_clf = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_grid=param_grid,\n",
    "        verbose=grid_search_verbosity,\n",
    "        scoring='roc_auc',\n",
    "        return_train_score=True,\n",
    "        cv=cv_list,\n",
    "    )\n",
    "\n",
    "    rf_clf.fit(X_train_std, y_train)\n",
    "    \n",
    "    # get best score from estimator on that fold and compare to old best score\n",
    "    current_best_score = rf_clf.best_score_\n",
    "    logger.info(f'Best score on inner fold: {current_best_score}')\n",
    "    #logger.info(f\"CV results on outer fold {outer_fold} for best model {rf_clf.cv_results_['params'][rf_clf.best_index_]}\")\n",
    "    logger.debug(f'All CV results on fold {outer_fold}: {rf_clf.cv_results_}')\n",
    "    \n",
    "    if current_best_score > best_score:\n",
    "        logger.info(f'New best score!')\n",
    "        \n",
    "        best_score = current_best_score\n",
    "        best_hparams = rf_clf.best_params_\n",
    "        logger.info(f'New best parameters on fold {outer_fold}: {rf_clf.best_params_}')\n",
    "    else:\n",
    "        logger.info(f'Best parameters still the same on fold {outer_fold}: {best_hparams}')\n",
    "        \n",
    "    best_rf = RandomForestClassifier(**best_hparams)\n",
    "    best_rf.fit(X_train_std, y_train)\n",
    "    predictions = best_rf.predict(X_test_std)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    scores.append(score)\n",
    "    logger.info(f'Test AUC-ROC on fold {outer_fold} with best hparams: {score}')\n",
    "    outer_fold += 1\n",
    "\n",
    "final_mean_score = round(np.array(scores).mean(), 4)\n",
    "print(f'Final mean score: {final_mean_score}')\n",
    "logger.info(f'Final AUC-ROC score (mean over 5 folds): {final_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5104"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_kf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "final_scores = []\n",
    "for train_index, test_index in final_kf.split(X, y, groups=split_criterion):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # standardize/normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    # fit data on training set\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    # standardize test data as well\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    \n",
    "    \n",
    "    rf = RandomForestClassifier(**{'criterion': 'gini', 'max_depth': 32, 'max_features': None, 'n_estimators': 700, 'n_jobs': -1, 'random_state': 21})\n",
    "    rf.fit(X_train_std, y_train)\n",
    "    predictions = rf.predict(X_test_std)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    final_scores.append(score)\n",
    "\n",
    "round(np.array(final_scores).mean(), 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T08:37:28.880520Z",
     "start_time": "2023-08-31T08:36:48.037886Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_dict = {'dummy':{'auc':[],\n",
    "                        'fprs':[],\n",
    "                        'tprs':[],\n",
    "                        'proba':[],\n",
    "                        'label':[]},\n",
    "                'rf':{  'auc':[],\n",
    "                        'fprs':[],\n",
    "                        'tprs':[],\n",
    "                        'proba':[],\n",
    "                        'label':[]},\n",
    "              }\n",
    "for f in range(folds):\n",
    "    # TODO: redo as stratifiedkfold over subjects\n",
    "    subjkeys = list(set(label_arr[:, 0]))\n",
    "    # set seeds (maybe define it as utils)\n",
    "    random.seed(f)\n",
    "    np.random.seed(f)\n",
    "    subjkeys = np.random.permutation(subjkeys) #random shuffling\n",
    "    \n",
    "    N_totalsub = len(subjkeys)\n",
    "    N_trainsub = round(0.8*N_totalsub)\n",
    "    N_validsub = round(0.1*N_totalsub)\n",
    "    N_testsub = N_totalsub - N_trainsub - N_validsub\n",
    "\n",
    "\n",
    "    N_train_sub = subjkeys[:N_trainsub]\n",
    "    N_val_sub = subjkeys[N_trainsub:N_trainsub + N_validsub]\n",
    "    N_test_sub = subjkeys[N_trainsub + N_validsub: N_trainsub + N_validsub + N_testsub]\n",
    "    X_train = data_arr_rf[np.isin(label_arr[:, 0], N_train_sub)]\n",
    "    X_val = data_arr_rf[np.isin(label_arr[:, 0], N_val_sub)]\n",
    "    X_test = data_arr_rf[np.isin(label_arr[:, 0], N_test_sub)]\n",
    "    y_train = label_arr[np.isin(label_arr[:, 0], N_train_sub)]\n",
    "    y_val = label_arr[np.isin(label_arr[:, 0], N_val_sub)]\n",
    "    y_test = label_arr[np.isin(label_arr[:, 0], N_test_sub)]\n",
    "        \n",
    "    # baseline \n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(X_train,np.array(y_train[:, 2], dtype=int))\n",
    "    dummy_proba = dummy_clf.predict_proba(X_test)\n",
    "    fpr, tpr, _ = metrics.roc_curve(np.array(y_test[:, 2], dtype=int), dummy_proba[:,1], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    metric_dict['dummy']['auc'].append(auc)\n",
    "    metric_dict['dummy']['fprs'].append(fpr)\n",
    "    metric_dict['dummy']['tprs'].append(tpr)\n",
    "    metric_dict['dummy']['proba'].append(dummy_proba)\n",
    "    metric_dict['dummy']['label'].append(y_test)\n",
    "    \n",
    "    # rf\n",
    "    pred_proba, best_parameters, rf = evaluate_rf.evaluate_rf(X_train, X_val, X_test,\n",
    "                                                          np.array(y_train[:, 2], dtype=int), \n",
    "                                                          np.array(y_val[:, 2], dtype=int))\n",
    "    fpr, tpr, _ = metrics.roc_curve(np.array(y_test[:, 2], dtype=int), pred_proba[:,1], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    metric_dict['rf']['auc'].append(auc)\n",
    "    metric_dict['rf']['fprs'].append(fpr)\n",
    "    metric_dict['rf']['tprs'].append(tpr)\n",
    "    metric_dict['rf']['proba'].append(pred_proba)\n",
    "    metric_dict['rf']['label'].append(y_test)\n",
    "    \n",
    "    \n",
    "    #print('auc: ' + str(auc))\n",
    "    aucs.append(auc)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    \n",
    "    baseline_accs.append(dummy_clf.score(X_test, np.array(y_test[:, 2], dtype=int)))\n",
    "    rf_accs.append(rf.score(X_test, np.array(y_test[:, 2], dtype=int)))\n",
    "    print('baseline: ' + str(baseline_accs[-1]) + ' vs. ' + str(rf_accs[-1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
